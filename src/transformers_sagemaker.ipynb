{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63ec4243-d555-4337-9099-51f47707ae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# import IPython\n",
    "# !conda install -c conda-forge ipywidgets -y\n",
    "# IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e58631b-de5b-4a94-baa1-5b5fbc899d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install datasets[s3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3a0fb6e1-9268-4a1b-9ba2-c12ecf1db685",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from datasets.filesystems import S3FileSystem\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "from sagemaker import TrainingJobAnalytics\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c8243d49-beac-40c1-86d2-eaf80c76682d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker bucket: sagemaker-godeltech\n",
      "sagemaker session region: eu-west-1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import awswrangler as wr\n",
    "import numpy as np\n",
    "import botocore\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import gc\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import awswrangler as wr\n",
    "\n",
    "import warnings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "pd.options.mode.chained_assignment = None\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "sagemaker_session_bucket = 'sagemaker-godeltech'\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "#put SageMaker role here if you're running this notebook locally\n",
    "role = \n",
    "\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4faa150b-31b4-45a3-8a5f-b33b7e3008b8",
   "metadata": {},
   "outputs": [],
   "source": [
    " ##HERE WILL BE THE VARIABLES\n",
    "SEED = 1234\n",
    "TODAY = datetime.today().strftime(\"%Y%m%d\")\n",
    "TRAIN_PATH = f\"s3://{sagemaker_session_bucket}/data/train/train.csv\"\n",
    "VAL_PATH = f\"s3://{sagemaker_session_bucket}/data/validate/validate.csv\"\n",
    "TEST_PATH = f\"s3://{sagemaker_session_bucket}/data/test/test.csv\"\n",
    "S3_PREFIX = \"transformers\"\n",
    "CHECKPOINT_URI = f's3://{sagemaker_session_bucket}/{S3_PREFIX}/checkpoints'\n",
    "OUTPUT_PATH = f's3://{sagemaker_session_bucket}/{S3_PREFIX}/outputs_{TODAY}'\n",
    "\n",
    "MODEL = \"distilbert-base-uncased\"\n",
    "INSTANCE = \"ml.g5.xlarge\" # G5 is a NVIDIA A10G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "23899ce7-5e41-43a6-a55a-561fdadd9cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d5859f98-fd5d-414c-b6cb-98517d1571f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = wr.s3.read_csv([TRAIN_PATH])\n",
    "val = wr.s3.read_csv([VAL_PATH])\n",
    "test = wr.s3.read_csv([TEST_PATH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3718d13f-9ac1-4b0e-b75c-253716285233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1443900, 2), (360975, 2), (194641, 12))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, val.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d73abcfc-d857-4cf4-8443-923262192197",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['toxicity'] = train['toxicity'].astype('int')\n",
    "val['toxicity'] = val['toxicity'].astype('int')\n",
    "test_text = test[['comment_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d309a8d7-f513-4aa4-87e4-59dd30ca496c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d10b73386f24d88acd99c766f20635c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1444 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8d9b0edba70457ea3fedf169c153dbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/361 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4a3fbc423d14db98a8e088b0063f385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, cache_dir = '../tmp/AutoTokenizer');\n",
    "\n",
    "# create tokenization function\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"comment_text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# tokenize train and test datasets\n",
    "train_dataset = Dataset.from_pandas(train).map(tokenize, batched=True)\n",
    "val_dataset = Dataset.from_pandas(val).map(tokenize, batched=True)\n",
    "test_dataset = Dataset.from_pandas(test_sample).map(tokenize, batched=True)\n",
    "\n",
    "# set dataset format for PyTorch\n",
    "train_dataset =  train_dataset.rename_column(\"toxicity\", \"labels\")\n",
    "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "val_dataset = val_dataset.rename_column(\"toxicity\", \"labels\")\n",
    "val_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0352845-9907-47b5-9fc9-4f11372bd181",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = S3FileSystem()\n",
    "\n",
    "# save train_dataset to S3\n",
    "training_input_path = f's3://{sess.default_bucket()}/{S3_PREFIX}/train'\n",
    "# train_dataset.save_to_disk(training_input_path,fs=s3)\n",
    "\n",
    "# save val_dataset to S3\n",
    "val_input_path = f's3://{sess.default_bucket()}/{S3_PREFIX}/validate'\n",
    "# val_dataset.save_to_disk(val_input_path,fs=s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83985865-01e8-425b-9d93-2f77379377e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters={\n",
    "    \"epochs\": 1,                            # number of training epochs\n",
    "    \"train_batch_size\": 32,                 # training batch size\n",
    "    \"model_name\": MODEL,                    # name of pretrained model\n",
    "    'do_train': True,\n",
    "    'do_eval': True,\n",
    "    'output_dir':'/opt/ml/checkpoints'\n",
    "}\n",
    "\n",
    "# # configuration for running training on smdistributed Data Parallel\n",
    "# distribution = {'smdistributed':{'dataparallel':{ 'enabled': True }}}\n",
    "\n",
    "# define metrics definitions\n",
    "metric_definitions=[\n",
    "    {'Name': 'loss', 'Regex': \"'loss': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'learning_rate', 'Regex': \"'learning_rate': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_loss', 'Regex': \"'eval_loss': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_f1', 'Regex': \"'eval_f1': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_roc_auc', 'Regex': \"'eval_roc_auc': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'epoch', 'Regex': \"'epoch': ([0-9]+(.|e\\-)[0-9]+),?\"}\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "994b58c0-1e49-4296-a182-21bd439c352f",
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator = HuggingFace(\n",
    "        entry_point=\"transformers_trainer.py\",      # fine-tuning script to use in training job\n",
    "        source_dir=\"./\",                            # directory where fine-tuning script is stored\n",
    "        instance_type=INSTANCE,                     # instance type (parallelism supports only by P3-family of GPUs)\n",
    "        instance_count=1,                           # number of instances\n",
    "        role=role,                                  # IAM role used in training job to acccess AWS resources (S3)\n",
    "        checkpoint_s3_uri=CHECKPOINT_URI,\n",
    "        output_path=OUTPUT_PATH,\n",
    "        use_spot_instances=True,\n",
    "        save_steps = 5000,\n",
    "        max_wait=6*60*60,                             # max_wait should be equal to or greater than max_run in seconds\n",
    "        max_run=6*60*60,\n",
    "        transformers_version = '4.12.3',            # the transformers version used in the training job\n",
    "        pytorch_version      = '1.9.1',             # the pytorch_version version used in the training job\n",
    "        py_version           = 'py38',              # the python version used in the training job\n",
    "        metric_definitions=metric_definitions,\n",
    "        hyperparameters=hyperparameters             # hyperparameters to use in training job\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508bf7f8-3491-4e6d-bc0e-a2893bf023da",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "huggingface_estimator.fit({\"train\": training_input_path, \"test\": val_input_path}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7191ff28-f434-440a-8991-8cdfec1ad01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# job which is going to be attached to the estimator\n",
    "old_training_job_name='huggingface-pytorch-training-2022-09-20-07-31-55-400'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6e40da9-7b4a-40a9-988e-199a2245d4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2022-09-20 10:48:26 Starting - Preparing the instances for training\n",
      "2022-09-20 10:48:26 Downloading - Downloading input data\n",
      "2022-09-20 10:48:26 Training - Training image download completed. Training in progress.\n",
      "2022-09-20 10:48:26 Uploading - Uploading generated training model\n",
      "2022-09-20 10:48:26 Completed - Training job completed\n",
      "container image used for training job: \n",
      "763104351884.dkr.ecr.eu-west-1.amazonaws.com/huggingface-pytorch-training:1.9.1-transformers4.12.3-gpu-py38-cu111-ubuntu20.04\n",
      "\n",
      "s3 uri where the trained model is located: \n",
      "s3://sagemaker-godeltech/transformers/outputs_20220920/huggingface-pytorch-training-2022-09-20-07-31-55-400/output/model.tar.gz\n",
      "\n",
      "latest training job name for this estimator: \n",
      "huggingface-pytorch-training-2022-09-20-07-31-55-400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# attach old training job\n",
    "huggingface_estimator_loaded = Estimator.attach(old_training_job_name)\n",
    "\n",
    " # container image used for training job\n",
    "print(f\"container image used for training job: \\n{huggingface_estimator_loaded.image_uri}\\n\")\n",
    "\n",
    "# s3 uri where the trained model is located\n",
    "print(f\"s3 uri where the trained model is located: \\n{huggingface_estimator_loaded.model_data}\\n\")\n",
    "\n",
    "# latest training job name for this estimator\n",
    "print(f\"latest training job name for this estimator: \\n{huggingface_estimator_loaded.latest_training_job.name}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0bcf3d52-22b7-4ae1-8bcd-3639f71f490d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Captured metrics can be accessed as a Pandas dataframe\n",
    "df = TrainingJobAnalytics(training_job_name=huggingface_estimator_loaded.latest_training_job.name).dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa7494c1-9182-4b16-8473-a6224236287f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>metric_name</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>epoch</th>\n",
       "      <th>eval_f1</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_roc_auc</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5580.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.179060</td>\n",
       "      <td>0.1109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>6360.0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.938013</td>\n",
       "      <td>0.1115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>6180.0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.498274</td>\n",
       "      <td>0.1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5940.0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.058536</td>\n",
       "      <td>0.1129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>6960.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.257227</td>\n",
       "      <td>0.1134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric_name  timestamp  epoch  eval_f1  eval_loss  eval_roc_auc  \\\n",
       "28              5580.0   0.90      NaN        NaN           NaN   \n",
       "32              6360.0   0.94      NaN        NaN           NaN   \n",
       "31              6180.0   0.93      NaN        NaN           NaN   \n",
       "30              5940.0   0.92      NaN        NaN           NaN   \n",
       "35              6960.0   0.98      NaN        NaN           NaN   \n",
       "\n",
       "metric_name  learning_rate    loss  \n",
       "28                5.179060  0.1109  \n",
       "32                2.938013  0.1115  \n",
       "31                3.498274  0.1116  \n",
       "30                4.058536  0.1129  \n",
       "35                1.257227  0.1134  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_df = df.pivot(index=['timestamp'], columns=['metric_name'])['value'].reset_index()\n",
    "pivot_df.sort_values(by='loss').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "909215a6-8c2f-470b-9ae8-17cb8abb1e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mhuggingface_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minstance_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minstance_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstrategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0massemble_with\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moutput_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moutput_kms_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0maccept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_concurrent_transforms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_payload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvolume_kms_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Return a ``Transformer`` that uses this Model.\n",
       "\n",
       "Args:\n",
       "    instance_count (int): Number of EC2 instances to use.\n",
       "    instance_type (str): Type of EC2 instance to use, for example,\n",
       "        'ml.c4.xlarge'.\n",
       "    strategy (str): The strategy used to decide how to batch records in\n",
       "        a single request (default: None). Valid values: 'MultiRecord'\n",
       "        and 'SingleRecord'.\n",
       "    assemble_with (str): How the output is assembled (default: None).\n",
       "        Valid values: 'Line' or 'None'.\n",
       "    output_path (str): S3 location for saving the transform result. If\n",
       "        not specified, results are stored to a default bucket.\n",
       "    output_kms_key (str): Optional. KMS key ID for encrypting the\n",
       "        transform output (default: None).\n",
       "    accept (str): The accept header passed by the client to\n",
       "        the inference endpoint. If it is supported by the endpoint,\n",
       "        it will be the format of the batch transform output.\n",
       "    env (dict): Environment variables to be set for use during the\n",
       "        transform job (default: None).\n",
       "    max_concurrent_transforms (int): The maximum number of HTTP requests\n",
       "        to be made to each individual transform container at one time.\n",
       "    max_payload (int): Maximum size of the payload in a single HTTP\n",
       "        request to the container in MB.\n",
       "    tags (list[dict]): List of tags for labeling a transform job. If\n",
       "        none specified, then the tags used for the training job are used\n",
       "        for the transform job.\n",
       "    volume_kms_key (str): Optional. KMS key ID for encrypting the volume\n",
       "        attached to the ML compute instance (default: None).\n",
       "\u001b[0;31mFile:\u001b[0m      ~/.conda/envs/godel/lib/python3.9/site-packages/sagemaker/model.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?huggingface_model.transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836822f8-0124-479e-9c4d-b5b93a83731e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "godel:Python",
   "language": "python",
   "name": "conda-env-godel-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
