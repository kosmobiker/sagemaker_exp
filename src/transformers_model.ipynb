{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89695a9f-b52e-404a-8ddf-d54de7be0c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import awswrangler as wr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from transformers import DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "226ef930-9a6a-44be-a612-f0e9beb9f8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today I'm going to use cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Today I'm going to use {device.type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b41c8e03-7134-4bb8-a50a-d05c75217307",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "N_SAMPLES = 20000\n",
    "TODAY = datetime.today().strftime(\"%Y%m%d\")\n",
    "BUCKET_NAME = 'sagemaker-godeltech'\n",
    "TRAIN_PATH = f\"s3://{BUCKET_NAME}/data/train/train.csv\"\n",
    "VAL_PATH = f\"s3://{BUCKET_NAME}/data/validate/validate.csv\"\n",
    "TEST_PATH = f\"s3://{BUCKET_NAME}/data/test/test.csv\"\n",
    "VOCAB_PATH = \"lstm/vocab\"\n",
    "MODEL_PATH = \"lstm/models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "527db98c-c6f2-4ed5-a3b1-6f18f70dcdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "# del model\n",
    "# del Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7a48123-f123-4802-9578-b93977cb1e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = wr.s3.read_csv([TRAIN_PATH])\n",
    "val = wr.s3.read_csv([VAL_PATH])\n",
    "test = wr.s3.read_csv([TEST_PATH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b59afc66-ea22-4593-916a-80494f20f08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1443900, 2), (360975, 2), (194641, 12))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample = train.sample(N_SAMPLES, random_state=SEED, ignore_index=True)\n",
    "val_sample = val.sample(N_SAMPLES, random_state=SEED, ignore_index=True)\n",
    "train.shape, val.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6e2ab41-6d29-4ac3-9671-5346394aeedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample['toxicity'] = train_sample['toxicity'].astype('int')\n",
    "val_sample['toxicity'] = val_sample['toxicity'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b8378f8-c775-4f14-82b6-e26d66fc5c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4756d7f60c71460baf505a65e5418002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7df8460088da42a18e4c104a79ddd20c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\", cache_dir = '../tmp/AutoTokenizer');\n",
    "\n",
    "# create tokenization function\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"comment_text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# tokenize train and test datasets\n",
    "train_dataset = Dataset.from_pandas(train_sample).map(tokenize, batched=True)\n",
    "val_dataset = Dataset.from_pandas(val_sample).map(tokenize, batched=True)\n",
    "\n",
    "# set dataset format for PyTorch\n",
    "train_dataset =  train_dataset.rename_column(\"toxicity\", \"labels\")\n",
    "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "val_dataset = val_dataset.rename_column(\"toxicity\", \"labels\")\n",
    "val_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cf2ab22-e187-42a4-a54a-49de902a4d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2, cache_dir = '../tmp/AutoModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea4e9fea-6d3e-4240-b214-460f24243c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: comment_text. If comment_text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/studio-lab-user/.conda/envs/godel/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 20000\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1875\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1875/1875 1:12:51, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.189500</td>\n",
       "      <td>0.151890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.124700</td>\n",
       "      <td>0.144131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.092400</td>\n",
       "      <td>0.170952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: comment_text. If comment_text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../tmp/results/checkpoint-500\n",
      "Configuration saved in ../tmp/results/checkpoint-500/config.json\n",
      "Model weights saved in ../tmp/results/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ../tmp/results/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ../tmp/results/checkpoint-500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: comment_text. If comment_text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../tmp/results/checkpoint-1000\n",
      "Configuration saved in ../tmp/results/checkpoint-1000/config.json\n",
      "Model weights saved in ../tmp/results/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in ../tmp/results/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in ../tmp/results/checkpoint-1000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: comment_text. If comment_text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../tmp/results/checkpoint-1500\n",
      "Configuration saved in ../tmp/results/checkpoint-1500/config.json\n",
      "Model weights saved in ../tmp/results/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in ../tmp/results/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in ../tmp/results/checkpoint-1500/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../tmp/results/checkpoint-1000 (score: 0.14413145184516907).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1875, training_loss=0.12296106567382813, metrics={'train_runtime': 4373.2602, 'train_samples_per_second': 13.72, 'train_steps_per_second': 0.429, 'total_flos': 7948043919360000.0, 'train_loss': 0.12296106567382813, 'epoch': 3.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../tmp/results\",\n",
    "    logging_dir=\"../tmp/results/logs\",\n",
    "    evaluation_strategy = \"steps\",\n",
    "    save_strategy = \"steps\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    seed=SEED,\n",
    "    load_best_model_at_end=True,\n",
    "    eval_steps=500\n",
    "    \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "79b139f9-517e-4e46-93bf-96af1ee18b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = test[['comment_text', 'toxicity']][:100000]\n",
    "test_text['toxicity'] = test_text['toxicity'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5a7d4f81-1d23-47f9-a1dd-5081019b5c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f303cab10deb46758cdda6d48aeadf92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenize train and test datasets\n",
    "test_dataset = Dataset.from_pandas(test_text).map(tokenize, batched=True)\n",
    "\n",
    "# set dataset format for PyTorch\n",
    "test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f5989258-e953-4dc8-a30e-640f4dc7789e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: comment_text, toxicity. If comment_text, toxicity are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "outputs = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d377d0e2-a69d-492c-a5dd-e8d29625d705",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = outputs.predictions.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3d8965e7-e081-493b-a3df-547d9cdc03ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_true = test[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9ab41c2f-4931-407c-af82-ad5a780e4e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/sagemaker_exp/src/quality_calculator.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n",
      "/home/studio-lab-user/sagemaker_exp/src/quality_calculator.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n",
      "/home/studio-lab-user/sagemaker_exp/src/quality_calculator.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n",
      "/home/studio-lab-user/sagemaker_exp/src/quality_calculator.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n",
      "/home/studio-lab-user/sagemaker_exp/src/quality_calculator.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n",
      "/home/studio-lab-user/sagemaker_exp/src/quality_calculator.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n",
      "/home/studio-lab-user/sagemaker_exp/src/quality_calculator.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n",
      "/home/studio-lab-user/sagemaker_exp/src/quality_calculator.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n",
      "/home/studio-lab-user/sagemaker_exp/src/quality_calculator.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n",
      "/home/studio-lab-user/sagemaker_exp/src/quality_calculator.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n",
      "/home/studio-lab-user/sagemaker_exp/src/quality_calculator.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n",
      "/home/studio-lab-user/sagemaker_exp/src/quality_calculator.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n",
      "/home/studio-lab-user/sagemaker_exp/src/quality_calculator.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n",
      "/home/studio-lab-user/sagemaker_exp/src/quality_calculator.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n",
      "/home/studio-lab-user/sagemaker_exp/src/quality_calculator.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n",
      "/home/studio-lab-user/sagemaker_exp/src/quality_calculator.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n",
      "/home/studio-lab-user/sagemaker_exp/src/quality_calculator.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n",
      "/home/studio-lab-user/sagemaker_exp/src/quality_calculator.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subgroup</th>\n",
       "      <th>subgroup_size</th>\n",
       "      <th>subgroup_auc</th>\n",
       "      <th>bpsn_auc</th>\n",
       "      <th>bnsp_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>homosexual_gay_or_lesbian</td>\n",
       "      <td>122</td>\n",
       "      <td>0.752858</td>\n",
       "      <td>0.802220</td>\n",
       "      <td>0.848750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>black</td>\n",
       "      <td>227</td>\n",
       "      <td>0.764829</td>\n",
       "      <td>0.834398</td>\n",
       "      <td>0.829584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>white</td>\n",
       "      <td>382</td>\n",
       "      <td>0.765809</td>\n",
       "      <td>0.772912</td>\n",
       "      <td>0.890830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jewish</td>\n",
       "      <td>103</td>\n",
       "      <td>0.772830</td>\n",
       "      <td>0.857634</td>\n",
       "      <td>0.813311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>psychiatric_or_mental_illness</td>\n",
       "      <td>67</td>\n",
       "      <td>0.779487</td>\n",
       "      <td>0.837977</td>\n",
       "      <td>0.839451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>muslim</td>\n",
       "      <td>207</td>\n",
       "      <td>0.793257</td>\n",
       "      <td>0.879766</td>\n",
       "      <td>0.812535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>christian</td>\n",
       "      <td>313</td>\n",
       "      <td>0.819222</td>\n",
       "      <td>0.884357</td>\n",
       "      <td>0.833481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>520</td>\n",
       "      <td>0.820065</td>\n",
       "      <td>0.859077</td>\n",
       "      <td>0.859938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>471</td>\n",
       "      <td>0.840821</td>\n",
       "      <td>0.860521</td>\n",
       "      <td>0.878589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        subgroup  subgroup_size  subgroup_auc  bpsn_auc  \\\n",
       "2      homosexual_gay_or_lesbian            122      0.752858  0.802220   \n",
       "6                          black            227      0.764829  0.834398   \n",
       "7                          white            382      0.765809  0.772912   \n",
       "4                         jewish            103      0.772830  0.857634   \n",
       "8  psychiatric_or_mental_illness             67      0.779487  0.837977   \n",
       "5                         muslim            207      0.793257  0.879766   \n",
       "3                      christian            313      0.819222  0.884357   \n",
       "1                         female            520      0.820065  0.859077   \n",
       "0                           male            471      0.840821  0.860521   \n",
       "\n",
       "   bnsp_auc  \n",
       "2  0.848750  \n",
       "6  0.829584  \n",
       "7  0.890830  \n",
       "4  0.813311  \n",
       "8  0.839451  \n",
       "5  0.812535  \n",
       "3  0.833481  \n",
       "1  0.859938  \n",
       "0  0.878589  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL SCORE FOR LSTM IS 0.841515555294606\n"
     ]
    }
   ],
   "source": [
    "from quality_calculator import compute_bias_metrics_for_model, calculate_overall_auc, get_final_metric\n",
    "\n",
    "\n",
    "oof_name = 'predicted_target'\n",
    "identity_columns = ['male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish', 'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "test_true[oof_name] = y_pred\n",
    "#evaluation\n",
    "bias_metrics_df = compute_bias_metrics_for_model(test_true, identity_columns, oof_name, 'toxicity')\n",
    "display(bias_metrics_df)\n",
    "FINAL_SCORE = get_final_metric(bias_metrics_df, calculate_overall_auc(test_true, oof_name))\n",
    "print(f\"FINAL SCORE FOR LSTM IS {FINAL_SCORE}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e125e564-6dd8-44f3-94de-ea8ed600a1c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "godel:Python",
   "language": "python",
   "name": "conda-env-godel-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
