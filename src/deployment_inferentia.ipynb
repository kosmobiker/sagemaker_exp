{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "565c21f1-685a-40e3-a8e5-25cff2ff0fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import sagemaker\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from pathlib import Path\n",
    "\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "from sagemaker.predictor import Predictor\n",
    "from datetime import datetime\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21ef473e-6c0f-458b-8e1f-5fc73ddeb991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker bucket: sagemaker-godeltech\n",
      "sagemaker session region: eu-west-1\n"
     ]
    }
   ],
   "source": [
    "sess = sagemaker.Session()\n",
    "sagemaker_session_bucket = 'sagemaker-godeltech'\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "#put SageMaker role here if you're running this notebook locally\n",
    "role = ''\n",
    "\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b031e6f-eba8-45c5-818e-e58cd18e2799",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'unitary/toxic-bert'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7bc3e7d3-0de8-46c5-8647-eac6a858e5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, cache_dir = '../tmp/AutoTokenizer')  \n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME,\n",
    "                                                           cache_dir = '../tmp/AutoModel',\n",
    "                                                           return_dict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bcd50ff3-a0c3-43a7-88a1-e3519cdbe134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory for model artifacts\n",
    "Path(\"../tmp/traced_model/\").mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5c8bc54-f98f-4ed0-94bd-aef9f0d64d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare sample input for jit model tracing\n",
    "seq = \"Godel technologies: Sage Maker: this is just an example for PyTorch\"\n",
    "max_length = 512\n",
    "\n",
    "tokenized_sequence_pair = tokenizer.encode_plus(\n",
    "    seq, max_length=max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "example = tokenized_sequence_pair[\"input_ids\"], tokenized_sequence_pair[\"attention_mask\"]\n",
    "\n",
    "traced_model = torch.jit.trace(model.eval(), example)\n",
    "traced_model.save(\"../tmp/traced_model/model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1c4c2a7-15a9-4d83-9c8e-5bd4cfc8e880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "./\n",
      "./model.pth\n",
      "./traced_model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!tar -czvf ../tmp/traced_model.tar.gz -C ../tmp/traced_model . && mv ../tmp/traced_model.tar.gz ../tmp/traced_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4563045c-4585-4932-b7a6-0de3fa8a3ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model_url = sess.upload_data(\n",
    "    path=\"../tmp/traced_model/traced_model.tar.gz\",\n",
    "    key_prefix=\"transformers/neuron-experiments/traced-model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "60fbd5d6-7e8c-42e0-9fdc-107f39d55c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"neuron-experiments\"\n",
    "flavour = \"normal\"\n",
    "date_string = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "normal_sm_model = PyTorchModel(\n",
    "    model_data=traced_model_url,\n",
    "    predictor_cls=Predictor,\n",
    "    framework_version=\"1.8.1\",\n",
    "    role=role,\n",
    "    sagemaker_session=sess,\n",
    "    entry_point=\"inference_normal.py\",\n",
    "    source_dir=\"./\",\n",
    "    py_version=\"py3\",\n",
    "    name=f\"{flavour}-toxicbert-{date_string}\",\n",
    "    env={\"SAGEMAKER_CONTAINER_LOG_LEVEL\": \"10\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2eab9408-9656-456b-b19d-af608d1a15ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!READY!\n"
     ]
    }
   ],
   "source": [
    "hardware = \"g4dn\"\n",
    "\n",
    "normal_predictor = normal_sm_model.deploy(\n",
    "    instance_type=\"ml.g4dn.xlarge\",\n",
    "    initial_instance_count=1,\n",
    "    endpoint_name=f\"toxicbert-{flavour}-{hardware}-{date_string}\",\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer(),\n",
    ")\n",
    "print('READY!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2c506f54-39eb-4621-aa8c-817340a80ddc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (0) from primary with message \"Your invocation timed out while waiting for a response from container primary. Review the latency metrics for each container in Amazon CloudWatch, resolve the issue, and try again.\". See https://eu-west-1.console.aws.amazon.com/cloudwatch/home?region=eu-west-1#logEventViewer:group=/aws/sagemaker/Endpoints/toxicbert-normal-g4dn-202209-2611-4428 in account 798631296162 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m payload \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124maccording to contract invoices have to be payed within 15 day, no exceptions for public holidays were described. paying on Tuesday, 16th seems to be a breach of contract. Viktoryia Charnianina please correct me if I\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm wrong\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mnormal_predictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/godel/lib/python3.9/site-packages/sagemaker/predictor.py:161\u001b[0m, in \u001b[0;36mPredictor.predict\u001b[0;34m(self, data, initial_args, target_model, target_variant, inference_id)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m\"\"\"Return the inference from the specified endpoint.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;124;03m        as is.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    158\u001b[0m request_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_request_args(\n\u001b[1;32m    159\u001b[0m     data, initial_args, target_model, target_variant, inference_id\n\u001b[1;32m    160\u001b[0m )\n\u001b[0;32m--> 161\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_runtime_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_response(response)\n",
      "File \u001b[0;32m~/.conda/envs/godel/lib/python3.9/site-packages/botocore/client.py:508\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    506\u001b[0m     )\n\u001b[1;32m    507\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 508\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/godel/lib/python3.9/site-packages/botocore/client.py:915\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    913\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m parsed_response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    914\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m--> 915\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (0) from primary with message \"Your invocation timed out while waiting for a response from container primary. Review the latency metrics for each container in Amazon CloudWatch, resolve the issue, and try again.\". See https://eu-west-1.console.aws.amazon.com/cloudwatch/home?region=eu-west-1#logEventViewer:group=/aws/sagemaker/Endpoints/toxicbert-normal-g4dn-202209-2611-4428 in account 798631296162 for more information."
     ]
    }
   ],
   "source": [
    "payload = \"\"\"according to contract invoices have to be payed within 15 day, no exceptions for public holidays were described. paying on Tuesday, 16th seems to be a breach of contract. Viktoryia Charnianina please correct me if I'm wrong\"\"\"\n",
    "normal_predictor.predict(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd11b57d-b4b7-4f54-ae70-86c91af9e7e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "godel:Python",
   "language": "python",
   "name": "conda-env-godel-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
