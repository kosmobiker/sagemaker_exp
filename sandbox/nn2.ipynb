{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd23e2fa-2523-4a5d-aff5-4fe89c11a352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import os\n",
    "import random\n",
    "\n",
    "import re, string\n",
    "from typing import Dict\n",
    "\n",
    "import torch, torchtext\n",
    "import torchvision.models as models\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchtext.vocab import GloVe\n",
    "from torch import nn, optim\n",
    "from torch.nn import Module, Embedding, LSTM, RNN, GRU, Linear, Sequential, Dropout\n",
    "from torch.nn.functional import sigmoid, relu, elu, tanh\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torch.nn.utils.rnn import PackedSequence\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "SEED = 1234\n",
    "N_SAMPLES = 100_000\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "pd.options.mode.chained_assignment = None\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f30d61b1-f4d3-4aa0-8c02-35cdf5187bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23364c0f-85aa-44e4-b6e2-9b6eba0c560a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e9f2a61-7c17-4cd1-9a21-6245d853f430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>split</th>\n",
       "      <th>created_date</th>\n",
       "      <th>publication_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>transgender</th>\n",
       "      <th>other_gender</th>\n",
       "      <th>heterosexual</th>\n",
       "      <th>homosexual_gay_or_lesbian</th>\n",
       "      <th>bisexual</th>\n",
       "      <th>other_sexual_orientation</th>\n",
       "      <th>christian</th>\n",
       "      <th>jewish</th>\n",
       "      <th>muslim</th>\n",
       "      <th>hindu</th>\n",
       "      <th>buddhist</th>\n",
       "      <th>atheist</th>\n",
       "      <th>other_religion</th>\n",
       "      <th>black</th>\n",
       "      <th>white</th>\n",
       "      <th>asian</th>\n",
       "      <th>latino</th>\n",
       "      <th>other_race_or_ethnicity</th>\n",
       "      <th>physical_disability</th>\n",
       "      <th>intellectual_or_learning_disability</th>\n",
       "      <th>psychiatric_or_mental_illness</th>\n",
       "      <th>other_disability</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1083994</td>\n",
       "      <td>He got his money... now he lies in wait till after the election in 2 yrs.... dirty politicians need to be afraid of Tar and feathers again... but they aren't and so the people get screwed.</td>\n",
       "      <td>train</td>\n",
       "      <td>2017-03-06 15:21:53.675241+00</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>317120</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.373134</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.343284</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>650904</td>\n",
       "      <td>Mad dog will surely put the liberals in mental hospitals. Boorah</td>\n",
       "      <td>train</td>\n",
       "      <td>2016-12-02 16:44:21.329535+00</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154086</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.092105</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5902188</td>\n",
       "      <td>And Trump continues his lifelong cowardice by not making this announcement himself.\\n\\nWhat an awful human being .....</td>\n",
       "      <td>train</td>\n",
       "      <td>2017-09-05 19:05:32.341360+00</td>\n",
       "      <td>55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374342</td>\n",
       "      <td>approved</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7084460</td>\n",
       "      <td>\"while arresting a man for resisting arrest\".\\n\\nIf you cop-suckers can't see a problem with this, then go suck the barrel of a Glock.</td>\n",
       "      <td>test</td>\n",
       "      <td>2016-11-01 16:53:33.561631+00</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149218</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.592105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5410943</td>\n",
       "      <td>Tucker and Paul are both total bad ass mofo's.</td>\n",
       "      <td>train</td>\n",
       "      <td>2017-06-14 05:08:21.997315+00</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>344096</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.337500</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.487500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  \\\n",
       "0  1083994   \n",
       "1   650904   \n",
       "2  5902188   \n",
       "3  7084460   \n",
       "4  5410943   \n",
       "\n",
       "                                                                                                                                                                                   comment_text  \\\n",
       "0  He got his money... now he lies in wait till after the election in 2 yrs.... dirty politicians need to be afraid of Tar and feathers again... but they aren't and so the people get screwed.   \n",
       "1                                                                                                                              Mad dog will surely put the liberals in mental hospitals. Boorah   \n",
       "2                                                                        And Trump continues his lifelong cowardice by not making this announcement himself.\\n\\nWhat an awful human being .....   \n",
       "3                                                        \"while arresting a man for resisting arrest\".\\n\\nIf you cop-suckers can't see a problem with this, then go suck the barrel of a Glock.   \n",
       "4                                                                                                                                                Tucker and Paul are both total bad ass mofo's.   \n",
       "\n",
       "   split                   created_date  publication_id  parent_id  \\\n",
       "0  train  2017-03-06 15:21:53.675241+00              21        NaN   \n",
       "1  train  2016-12-02 16:44:21.329535+00              21        NaN   \n",
       "2  train  2017-09-05 19:05:32.341360+00              55        NaN   \n",
       "3   test  2016-11-01 16:53:33.561631+00              13        NaN   \n",
       "4  train  2017-06-14 05:08:21.997315+00              21        NaN   \n",
       "\n",
       "   article_id    rating  funny  wow  sad  likes  disagree  toxicity  \\\n",
       "0      317120  approved      0    0    0      2         0  0.373134   \n",
       "1      154086  approved      0    0    1      2         0  0.605263   \n",
       "2      374342  approved      1    0    2      3         7  0.666667   \n",
       "3      149218  approved      0    0    0      0         0  0.815789   \n",
       "4      344096  approved      0    0    0      1         0  0.550000   \n",
       "\n",
       "   severe_toxicity   obscene  sexual_explicit  identity_attack    insult  \\\n",
       "0         0.044776  0.089552         0.014925         0.000000  0.343284   \n",
       "1         0.013158  0.065789         0.013158         0.092105  0.565789   \n",
       "2         0.015873  0.031746         0.000000         0.047619  0.666667   \n",
       "3         0.065789  0.552632         0.592105         0.000000  0.684211   \n",
       "4         0.037500  0.337500         0.275000         0.037500  0.487500   \n",
       "\n",
       "     threat  male  female  transgender  other_gender  heterosexual  \\\n",
       "0  0.014925   NaN     NaN          NaN           NaN           NaN   \n",
       "1  0.065789   NaN     NaN          NaN           NaN           NaN   \n",
       "2  0.000000   NaN     NaN          NaN           NaN           NaN   \n",
       "3  0.105263   NaN     NaN          NaN           NaN           NaN   \n",
       "4  0.000000   NaN     NaN          NaN           NaN           NaN   \n",
       "\n",
       "   homosexual_gay_or_lesbian  bisexual  other_sexual_orientation  christian  \\\n",
       "0                        NaN       NaN                       NaN        NaN   \n",
       "1                        NaN       NaN                       NaN        NaN   \n",
       "2                        NaN       NaN                       NaN        NaN   \n",
       "3                        NaN       NaN                       NaN        NaN   \n",
       "4                        NaN       NaN                       NaN        NaN   \n",
       "\n",
       "   jewish  muslim  hindu  buddhist  atheist  other_religion  black  white  \\\n",
       "0     NaN     NaN    NaN       NaN      NaN             NaN    NaN    NaN   \n",
       "1     NaN     NaN    NaN       NaN      NaN             NaN    NaN    NaN   \n",
       "2     NaN     NaN    NaN       NaN      NaN             NaN    NaN    NaN   \n",
       "3     NaN     NaN    NaN       NaN      NaN             NaN    NaN    NaN   \n",
       "4     NaN     NaN    NaN       NaN      NaN             NaN    NaN    NaN   \n",
       "\n",
       "   asian  latino  other_race_or_ethnicity  physical_disability  \\\n",
       "0    NaN     NaN                      NaN                  NaN   \n",
       "1    NaN     NaN                      NaN                  NaN   \n",
       "2    NaN     NaN                      NaN                  NaN   \n",
       "3    NaN     NaN                      NaN                  NaN   \n",
       "4    NaN     NaN                      NaN                  NaN   \n",
       "\n",
       "   intellectual_or_learning_disability  psychiatric_or_mental_illness  \\\n",
       "0                                  NaN                            NaN   \n",
       "1                                  NaN                            NaN   \n",
       "2                                  NaN                            NaN   \n",
       "3                                  NaN                            NaN   \n",
       "4                                  NaN                            NaN   \n",
       "\n",
       "   other_disability  identity_annotator_count  toxicity_annotator_count  \n",
       "0               NaN                         0                        67  \n",
       "1               NaN                         0                        76  \n",
       "2               NaN                         0                        63  \n",
       "3               NaN                         0                        76  \n",
       "4               NaN                         0                        80  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = pd.read_csv('../data/toxic_data.csv', chunksize=100000)\n",
    "df = pd.concat(chunks)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17df83e7-bc39-4c5b-81f0-68bf155d097a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comment_text'] = df['comment_text'].fillna(\"\")\n",
    "identity_columns = ['male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish', 'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "for col in identity_columns + ['toxicity']:\n",
    "    df.loc[:, col] = np.where(df[col] >= 0.5, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66e3ed1e-38cc-4da9-bca6-494ae5ff21c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1804875, 46), (194641, 46))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = df[df['split'] == 'train']\n",
    "test_df = df[df['split'] != 'train']\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c45d26f-d1c1-4b93-94d3-dc764661885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = df\n",
    "sample = train_df.sample(N_SAMPLES, random_state=SEED, ignore_index=True)\n",
    "train_text, val_text, train_label, val_label = train_test_split(sample['comment_text'], sample['toxicity'], test_size=0.2, random_state=SEED)\n",
    "# train_text, train_label = sample['comment_text'], sample['toxicity']\n",
    "test_text, test_label = test_df['comment_text'], test_df['toxicity']\n",
    "\n",
    "train_label = torch.tensor(train_label.values, dtype=torch.float32).to(device)\n",
    "val_label = torch.tensor(val_label.values, dtype=torch.float32).to(device) \n",
    "test_label = torch.tensor(test_label.values, dtype=torch.float32).to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccd05565-defd-4178-b086-667ef9cf4a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80000,), (194641,), 80000, 194641, (20000,), 20000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text.shape, test_text.shape, len(train_label), len(test_label), val_text.shape, len(val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78d9d9cb-af88-486e-a00b-dfde7b5c6816",
   "metadata": {},
   "outputs": [],
   "source": [
    "misspell_dict = {\"aren't\": \"are not\", \"can't\": \"cannot\", \"couldn't\": \"could not\",\n",
    "                 \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\",\n",
    "                 \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                 \"he'd\": \"he would\", \"he'll\": \"he will\", \"he's\": \"he is\",\n",
    "                 \"i'd\": \"I had\", \"i'll\": \"I will\", \"i'm\": \"I am\", \"isn't\": \"is not\",\n",
    "                 \"it's\": \"it is\", \"it'll\": \"it will\", \"i've\": \"I have\", \"let's\": \"let us\",\n",
    "                 \"mightn't\": \"might not\", \"mustn't\": \"must not\", \"shan't\": \"shall not\",\n",
    "                 \"she'd\": \"she would\", \"she'll\": \"she will\", \"she's\": \"she is\",\n",
    "                 \"shouldn't\": \"should not\", \"that's\": \"that is\", \"there's\": \"there is\",\n",
    "                 \"they'd\": \"they would\", \"they'll\": \"they will\", \"they're\": \"they are\",\n",
    "                 \"they've\": \"they have\", \"we'd\": \"we would\", \"we're\": \"we are\",\n",
    "                 \"weren't\": \"were not\", \"we've\": \"we have\", \"what'll\": \"what will\",\n",
    "                 \"what're\": \"what are\", \"what's\": \"what is\", \"what've\": \"what have\",\n",
    "                 \"where's\": \"where is\", \"who'd\": \"who would\", \"who'll\": \"who will\",\n",
    "                 \"who're\": \"who are\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                 \"won't\": \"will not\", \"wouldn't\": \"would not\", \"you'd\": \"you would\",\n",
    "                 \"you'll\": \"you will\", \"you're\": \"you are\", \"you've\": \"you have\",\n",
    "                 \"'re\": \" are\", \"wasn't\": \"was not\", \"we'll\": \" will\", \"tryin'\": \"trying\"}\n",
    "\n",
    "\n",
    "def _get_misspell(misspell_dict):\n",
    "    misspell_re = re.compile('(%s)' % '|'.join(misspell_dict.keys()))\n",
    "    return misspell_dict, misspell_re\n",
    "\n",
    "\n",
    "def replace_typical_misspell(text):\n",
    "    misspellings, misspellings_re = _get_misspell(misspell_dict)\n",
    "\n",
    "    def replace(match):\n",
    "        return misspellings[match.group(0)]\n",
    "\n",
    "    return misspellings_re.sub(replace, text)\n",
    "    \n",
    "\n",
    "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']',\n",
    "          '>', '%', '=', '#', '*', '+', '\\\\', '•', '~', '@', '£', '·', '_', '{', '}', '©', '^',\n",
    "          '®', '`', '<', '→', '°', '€', '™', '›', '♥', '←', '×', '§', '″', '′', 'Â', '█',\n",
    "          '½', 'à', '…', '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶',\n",
    "          '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '▒', '：', '¼',\n",
    "          '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲',\n",
    "          'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', '∙', '）', '↓', '、', '│', '（', '»', '，', '♪',\n",
    "          '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√']\n",
    "\n",
    "\n",
    "def clean_text(x):\n",
    "    x = str(x)\n",
    "    for punct in puncts + list(string.punctuation):\n",
    "        if punct in x:\n",
    "            x = x.replace(punct, f' {punct} ')\n",
    "    return x\n",
    "\n",
    "\n",
    "def clean_numbers(x):\n",
    "    return re.sub('\\d+', ' ', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f215f5f2-a071-4e3c-b736-1e242f553141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean misspellings\n",
    "train_text = train_text.apply(replace_typical_misspell)\n",
    "val_text = val_text.apply(replace_typical_misspell)\n",
    "test_text = test_text.apply(replace_typical_misspell)\n",
    "\n",
    "# clean the text\n",
    "train_text = train_text.apply(clean_text)\n",
    "val_text = val_text.apply(clean_text)\n",
    "test_text = test_text.apply(clean_text)\n",
    "\n",
    "# clean numbers\n",
    "train_text = train_text.apply(clean_numbers)\n",
    "val_text = val_text.apply(clean_numbers)\n",
    "test_text = test_text.apply(clean_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a16e6fed-323a-4563-a2ce-3ba57e1c7d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "counter = Counter()\n",
    "for line in train_text:\n",
    "    counter.update(tokenizer(line))\n",
    "    \n",
    "# Create a vocabulary with words seen at least 3 (min_freq) times\n",
    "vocab = torchtext.vocab.vocab(counter, min_freq=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7306873-fe3a-4899-bf58-8cdbfa9ccea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the unknown token and use it by default for unknown words\n",
    "unk_token = '<unk>'\n",
    "# vocab.insert_token(unk_token, 0)\n",
    "vocab.set_default_index(0)\n",
    "\n",
    "# Add the pad token Explanation https://huggingface.co/docs/transformers/pad_truncation\n",
    "pad_token = '<pad>'\n",
    "vocab.insert_token(pad_token, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9e1103d-bc7b-4cc5-9b20-86e71e2f0081",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_transform_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08110550-34c9-470e-96f9-acfb79cdc7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save vocab\n",
    "torch.save(vocab, 'vocab_obj_pytorch.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8593d17c-6ebe-4e54-a0f9-ab97ce4cde64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before transform:\n",
      "The part that is always difficult to take is when the Globe criticizes Trump with such indignation  .  \n",
      "  .  \n",
      "As if anybody has forgotten that this is the same Globe that was a serial enabler of Stephen Harper  .  \n",
      "  .  \n",
      "Not once  ,  \n",
      "Not twice  ,  \n",
      "Not three times  ,  \n",
      "  .  \n",
      "But yes  ,   four times in a row  !  \n",
      "  .  \n",
      "Talk about motes and beams  .    .    .  \n",
      "  .  \n",
      "Glad to see the Globe has got it right on Trump  ,   for sure  ,   but  ,   nonetheless  ,   the whole thing reeks of hypocrisy  .  \n",
      "After transform:\n",
      "[21, 1186, 0, 2, 161, 1496, 93, 622, 2, 37, 21, 884, 10015, 113, 320, 57, 10016, 26, 26, 45, 109, 3517, 722, 7984, 0, 65, 2, 21, 473, 884, 0, 87, 41, 10017, 7990, 6, 2122, 2096, 26, 26, 111, 1440, 44, 111, 4484, 44, 111, 392, 1615, 44, 26, 176, 760, 44, 2795, 1615, 180, 41, 2261, 36, 26, 1247, 155, 0, 10, 10018, 26, 26, 26, 26, 5310, 93, 47, 21, 884, 722, 1917, 34, 385, 20, 113, 44, 112, 883, 44, 176, 44, 3865, 44, 21, 1576, 207, 8103, 6, 1273, 26]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before transform:\\n{train_text.iloc[1666]}\")\n",
    "print(f\"After transform:\\n{text_transform_pipeline(train_text.iloc[1666])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6b31850-a51f-4b7a-99c2-2d9a3ee9710a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformText(text_list, max_len):\n",
    "    # Transform the text\n",
    "    transformed_data = [text_transform_pipeline(text)[:max_len] for text in text_list]\n",
    "\n",
    "    # Pad zeros if the text is shoter than max_len\n",
    "    for data in transformed_data:\n",
    "        data[len(data) : max_len] = np.ones(max_len - len(data))\n",
    "\n",
    "    return torch.tensor(transformed_data, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a784f62-21fe-4e2a-9b72-0ae2e517cb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS\n",
    "N_EPOCHES = 5\n",
    "max_len = 100\n",
    "batch_size = 128\n",
    "\n",
    "# Size of the state vectors\n",
    "lstm_hiden_size = 128\n",
    "dense_hiden_size = 4 * lstm_hiden_size\n",
    "\n",
    "# General NN training parameters\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6688220c-5cf2-4a7f-b5f0-4270c4e15951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_435/3562846554.py:9: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  return torch.tensor(transformed_data, dtype=torch.int64)\n"
     ]
    }
   ],
   "source": [
    "# Create data loaders\n",
    "train_dataset = TensorDataset(\n",
    "    transformText(train_text, max_len), train_label\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "val_dataset = TensorDataset(transformText(val_text, max_len), val_label)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "test_dataset = TensorDataset(transformText(test_text, max_len), test_label)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b282d16b-6544-49d1-ac3c-bb4c63116f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pretrained Word Embeddings ====> GloVe, FastText, CharNGram\n",
    "\n",
    "glove = GloVe(name=\"6B\", dim=300)\n",
    "embedding_matrix = glove.get_vecs_by_tokens(vocab.get_itos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a52cb61-d1f1-40d5-9c00-ebf234219d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([31203, 300])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f40b77b5-53f6-4a7b-9cef-1f39eb92c4bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31203"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embedding vector and vocabulary sizes\n",
    "embed_size = 300  # glove.6B.300d.txt\n",
    "vocab_size = len(vocab.get_itos())\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5abaf7bc-7ab0-4c62-bed6-179a3797f838",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialDropout(nn.Dropout2d):\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(2)    # (N, T, 1, K)\n",
    "        x = x.permute(0, 3, 2, 1)  # (N, K, 1, T)\n",
    "        x = super(SpatialDropout, self).forward(x)  # (N, K, 1, T), some features are masked\n",
    "        x = x.permute(0, 3, 2, 1)  # (N, T, 1, K)\n",
    "        x = x.squeeze(2)  # (N, T, K)\n",
    "        return x\n",
    "    \n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, embedding_matrix, lstm_hiden_size, dense_hiden_size, num_aux_targets):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        max_features = embedding_matrix.shape[0]\n",
    "        embed_size = embedding_matrix.shape[1]\n",
    "        \n",
    "        self.embedding = nn.Embedding(max_features, embed_size)\n",
    "        self.embedding.weight = nn.Parameter(embedding_matrix.clone().detach())\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        self.embedding_dropout = SpatialDropout(0.3)\n",
    "\n",
    "        self.lstm1 = nn.LSTM(embed_size, lstm_hiden_size, bidirectional=True, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(lstm_hiden_size * 2, lstm_hiden_size, bidirectional=True, batch_first=True)\n",
    "    \n",
    "        self.linear1 = nn.Linear(dense_hiden_size, dense_hiden_size)\n",
    "        self.linear2 = nn.Linear(dense_hiden_size, dense_hiden_size)\n",
    "        \n",
    "        self.linear_out = nn.Linear(dense_hiden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h_embedding = self.embedding(x)\n",
    "        h_embedding = self.embedding_dropout(h_embedding)\n",
    "        h_lstm1, _ = self.lstm1(h_embedding)\n",
    "        h_lstm2, _ = self.lstm2(h_lstm1)\n",
    "        \n",
    "        # global average pooling\n",
    "        avg_pool = torch.mean(h_lstm2, 1)\n",
    "        max_pool, _ = torch.max(h_lstm2, 1)\n",
    "        \n",
    "        h_conc = torch.cat((max_pool, avg_pool), 1)\n",
    "        h_conc_linear1  = relu(self.linear1(h_conc))\n",
    "        h_conc_linear2  = relu(self.linear2(h_conc))\n",
    "        \n",
    "        hidden = h_conc + h_conc_linear1 + h_conc_linear2       \n",
    "        result = self.linear_out(hidden)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6fd4e95e-c03d-469c-a2ff-57bbd3cdae0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(embedding_matrix, LSTM_UNITS, DENSE_HIDDEN_UNITS, num_aux_targets=6)\n",
    "# Setting our trainer\n",
    "trainer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# We will use Binary Cross-entropy loss\n",
    "cross_ent_loss = nn.BCEWithLogitsLoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51f08a1f-1eec-43ab-b784-3b21d68b5c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [06:29<00:00,  1.61it/s]\n",
      "100%|██████████| 157/157 [00:39<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Train_loss 0.0015035621473100036. Validation_loss 0.005463759508728981. Seconds 428.97328186035156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [06:33<00:00,  1.59it/s]\n",
      "100%|██████████| 157/157 [00:40<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1. Train_loss 0.001223735763086006. Validation_loss 0.005467379543185234. Seconds 434.7794041633606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [06:33<00:00,  1.59it/s]\n",
      "100%|██████████| 157/157 [00:40<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2. Train_loss 0.001136561413574964. Validation_loss 0.005464318069815636. Seconds 433.64313650131226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [06:32<00:00,  1.59it/s]\n",
      "100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3. Train_loss 0.001051815305883065. Validation_loss 0.0054622422873973845. Seconds 434.2382950782776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [06:33<00:00,  1.59it/s]\n",
      "100%|██████████| 157/157 [00:40<00:00,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4. Train_loss 0.0009717974937520921. Validation_loss 0.005448731726408005. Seconds 433.84892749786377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Get the compute device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(N_EPOCHES):\n",
    "    start = time.time()\n",
    "    training_loss = 0\n",
    "    val_loss = 0\n",
    "    model.train()\n",
    "    avg_loss = 0.\n",
    "\n",
    "    for data, target in tqdm(train_loader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(data)\n",
    "        loss = cross_ent_loss(output.squeeze(1), target)\n",
    "        trainer.zero_grad()\n",
    "        loss.backward()\n",
    "        trainer.step()\n",
    "        training_loss += loss.item()\n",
    "        \n",
    "    model.eval()\n",
    "    \n",
    "    for data, target in tqdm(val_loader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        val_predictions = torch.sigmoid(model(data))\n",
    "        loss = cross_ent_loss(val_predictions.squeeze(1), target)\n",
    "        val_loss += loss.item()\n",
    "        \n",
    "    # Let's take the average losses\n",
    "    training_loss = training_loss / len(train_label)\n",
    "    val_loss = val_loss / len(val_label)\n",
    "    \n",
    "    train_losses.append(training_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    end = time.time()\n",
    "    print(\n",
    "        f\"Epoch {epoch}. Train_loss {training_loss}. Validation_loss {val_loss}. Seconds {end-start}\"\n",
    "    )\n",
    "           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4672556a-20da-4c21-9f30-5e58c1e975f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label=\"Training Loss\")\n",
    "plt.plot(val_losses, label=\"Validation Loss\")\n",
    "plt.title(\"Loss values\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69935460-6a80-4be9-bad9-a36a1d8bbedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1521/1521 [06:31<00:00,  3.89it/s]\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "model.eval()\n",
    "test_predictions = []\n",
    "for data, target in tqdm(test_loader):\n",
    "    test_preds = model(data.to(device))\n",
    "    test_predictions.extend(\n",
    "        [sigmoid(test_pred[0]) for test_pred in test_preds.detach().cpu().numpy()]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a32e0dac-1c08-45a4-b113-5174e50efe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(test_predictions), len(test_predictions)\n",
    "oof_name = 'predicted_target'\n",
    "test_df[oof_name] = test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2fc61c64-0eb8-428e-a2fa-73da9096e688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subgroup</th>\n",
       "      <th>subgroup_size</th>\n",
       "      <th>subgroup_auc</th>\n",
       "      <th>bpsn_auc</th>\n",
       "      <th>bnsp_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>homosexual_gay_or_lesbian</td>\n",
       "      <td>1065</td>\n",
       "      <td>0.755119</td>\n",
       "      <td>0.658213</td>\n",
       "      <td>0.970030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>black</td>\n",
       "      <td>1519</td>\n",
       "      <td>0.764714</td>\n",
       "      <td>0.734151</td>\n",
       "      <td>0.959886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>white</td>\n",
       "      <td>2452</td>\n",
       "      <td>0.787396</td>\n",
       "      <td>0.737191</td>\n",
       "      <td>0.964790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>muslim</td>\n",
       "      <td>2040</td>\n",
       "      <td>0.789043</td>\n",
       "      <td>0.764039</td>\n",
       "      <td>0.955356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jewish</td>\n",
       "      <td>835</td>\n",
       "      <td>0.830204</td>\n",
       "      <td>0.841994</td>\n",
       "      <td>0.934570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>psychiatric_or_mental_illness</td>\n",
       "      <td>511</td>\n",
       "      <td>0.862136</td>\n",
       "      <td>0.847297</td>\n",
       "      <td>0.946347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>5155</td>\n",
       "      <td>0.869597</td>\n",
       "      <td>0.877915</td>\n",
       "      <td>0.933856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>4386</td>\n",
       "      <td>0.873907</td>\n",
       "      <td>0.862300</td>\n",
       "      <td>0.945150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>christian</td>\n",
       "      <td>4226</td>\n",
       "      <td>0.876090</td>\n",
       "      <td>0.901393</td>\n",
       "      <td>0.919224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        subgroup  subgroup_size  subgroup_auc  bpsn_auc  \\\n",
       "2      homosexual_gay_or_lesbian           1065      0.755119  0.658213   \n",
       "6                          black           1519      0.764714  0.734151   \n",
       "7                          white           2452      0.787396  0.737191   \n",
       "5                         muslim           2040      0.789043  0.764039   \n",
       "4                         jewish            835      0.830204  0.841994   \n",
       "8  psychiatric_or_mental_illness            511      0.862136  0.847297   \n",
       "1                         female           5155      0.869597  0.877915   \n",
       "0                           male           4386      0.873907  0.862300   \n",
       "3                      christian           4226      0.876090  0.901393   \n",
       "\n",
       "   bnsp_auc  \n",
       "2  0.970030  \n",
       "6  0.959886  \n",
       "7  0.964790  \n",
       "5  0.955356  \n",
       "4  0.934570  \n",
       "8  0.946347  \n",
       "1  0.933856  \n",
       "0  0.945150  \n",
       "3  0.919224  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SUBGROUP_AUC = 'subgroup_auc'\n",
    "BPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\n",
    "BNSP_AUC = 'bnsp_auc'  # stands for background negative, subgroup positive\n",
    "\n",
    "def compute_auc(y_true, y_pred):\n",
    "    try:\n",
    "        return roc_auc_score(y_true, y_pred)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "def compute_subgroup_auc(df, subgroup, label, oof_name):\n",
    "    subgroup_examples = df[df[subgroup]]\n",
    "    return compute_auc(subgroup_examples[label], subgroup_examples[oof_name])\n",
    "\n",
    "def compute_bpsn_auc(df, subgroup, label, oof_name):\n",
    "    \"\"\"Computes the AUC of the within-subgroup negative examples and the background positive examples.\"\"\"\n",
    "    subgroup_negative_examples = df[df[subgroup] & ~df[label]]\n",
    "    non_subgroup_positive_examples = df[~df[subgroup] & df[label]]\n",
    "    examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n",
    "    return compute_auc(examples[label], examples[oof_name])\n",
    "\n",
    "def compute_bnsp_auc(df, subgroup, label, oof_name):\n",
    "    \"\"\"Computes the AUC of the within-subgroup positive examples and the background negative examples.\"\"\"\n",
    "    subgroup_positive_examples = df[df[subgroup] & df[label]]\n",
    "    non_subgroup_negative_examples = df[~df[subgroup] & ~df[label]]\n",
    "    examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n",
    "    return compute_auc(examples[label], examples[oof_name])\n",
    "\n",
    "def compute_bias_metrics_for_model(dataset,\n",
    "                                   subgroups,\n",
    "                                   model,\n",
    "                                   label_col,\n",
    "                                   include_asegs=False):\n",
    "    \"\"\"Computes per-subgroup metrics for all subgroups and one model.\"\"\"\n",
    "    records = []\n",
    "    for subgroup in subgroups:\n",
    "        record = {\n",
    "            'subgroup': subgroup,\n",
    "            'subgroup_size': len(dataset[dataset[subgroup]])\n",
    "        }\n",
    "        record[SUBGROUP_AUC] = compute_subgroup_auc(dataset, subgroup, label_col, model)\n",
    "        record[BPSN_AUC] = compute_bpsn_auc(dataset, subgroup, label_col, model)\n",
    "        record[BNSP_AUC] = compute_bnsp_auc(dataset, subgroup, label_col, model)\n",
    "        records.append(record)\n",
    "    return pd.DataFrame(records).sort_values('subgroup_auc', ascending=True)\n",
    "bias_metrics_df = compute_bias_metrics_for_model(test_df, identity_columns, oof_name, 'toxicity')\n",
    "bias_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f32180a1-c18b-459e-ada0-61dc1f4df5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL SCORE IS 0.8683721548044423\n"
     ]
    }
   ],
   "source": [
    "def calculate_overall_auc(df, oof_name):\n",
    "    true_labels = df['toxicity']\n",
    "    predicted_labels = df[oof_name]\n",
    "    return roc_auc_score(true_labels, predicted_labels)\n",
    "\n",
    "def power_mean(series, p):\n",
    "    total = sum(np.power(series, p))\n",
    "    return np.power(total / len(series), 1 / p)\n",
    "\n",
    "def get_final_metric(bias_df, overall_auc, POWER=-5, OVERALL_MODEL_WEIGHT=0.25):\n",
    "    bias_score = np.average([\n",
    "        power_mean(bias_df[SUBGROUP_AUC], POWER),\n",
    "        power_mean(bias_df[BPSN_AUC], POWER),\n",
    "        power_mean(bias_df[BNSP_AUC], POWER)\n",
    "    ])\n",
    "    return (OVERALL_MODEL_WEIGHT * overall_auc) + ((1 - OVERALL_MODEL_WEIGHT) * bias_score)\n",
    "FINAL_SCORE = get_final_metric(bias_metrics_df, calculate_overall_auc(test_df, oof_name))\n",
    "print(f\"FINAL SCORE IS {FINAL_SCORE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea79382-2434-4d3b-ba83-831c4a8f8956",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "godel:Python",
   "language": "python",
   "name": "conda-env-godel-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
