{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd23e2fa-2523-4a5d-aff5-4fe89c11a352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import os\n",
    "import random\n",
    "\n",
    "from typing import Dict\n",
    "\n",
    "import torch, torchtext\n",
    "import torchvision.models as models\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchtext.vocab import GloVe\n",
    "from torch import nn, optim\n",
    "from torch.nn import Module, Embedding, LSTM, RNN, GRU, Linear, Sequential, Dropout\n",
    "from torch.nn.functional import sigmoid, relu, elu, tanh\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torch.nn.utils.rnn import PackedSequence\n",
    "\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "SEED = 1234\n",
    "N_SAMPLES = 1_000_000\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "pd.options.mode.chained_assignment = None\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f30d61b1-f4d3-4aa0-8c02-35cdf5187bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23364c0f-85aa-44e4-b6e2-9b6eba0c560a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e9f2a61-7c17-4cd1-9a21-6245d853f430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>split</th>\n",
       "      <th>created_date</th>\n",
       "      <th>publication_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>transgender</th>\n",
       "      <th>other_gender</th>\n",
       "      <th>heterosexual</th>\n",
       "      <th>homosexual_gay_or_lesbian</th>\n",
       "      <th>bisexual</th>\n",
       "      <th>other_sexual_orientation</th>\n",
       "      <th>christian</th>\n",
       "      <th>jewish</th>\n",
       "      <th>muslim</th>\n",
       "      <th>hindu</th>\n",
       "      <th>buddhist</th>\n",
       "      <th>atheist</th>\n",
       "      <th>other_religion</th>\n",
       "      <th>black</th>\n",
       "      <th>white</th>\n",
       "      <th>asian</th>\n",
       "      <th>latino</th>\n",
       "      <th>other_race_or_ethnicity</th>\n",
       "      <th>physical_disability</th>\n",
       "      <th>intellectual_or_learning_disability</th>\n",
       "      <th>psychiatric_or_mental_illness</th>\n",
       "      <th>other_disability</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1083994</td>\n",
       "      <td>He got his money... now he lies in wait till after the election in 2 yrs.... dirty politicians need to be afraid of Tar and feathers again... but they aren't and so the people get screwed.</td>\n",
       "      <td>train</td>\n",
       "      <td>2017-03-06 15:21:53.675241+00</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>317120</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.373134</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.343284</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>650904</td>\n",
       "      <td>Mad dog will surely put the liberals in mental hospitals. Boorah</td>\n",
       "      <td>train</td>\n",
       "      <td>2016-12-02 16:44:21.329535+00</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154086</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.092105</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5902188</td>\n",
       "      <td>And Trump continues his lifelong cowardice by not making this announcement himself.\\n\\nWhat an awful human being .....</td>\n",
       "      <td>train</td>\n",
       "      <td>2017-09-05 19:05:32.341360+00</td>\n",
       "      <td>55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374342</td>\n",
       "      <td>approved</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7084460</td>\n",
       "      <td>\"while arresting a man for resisting arrest\".\\n\\nIf you cop-suckers can't see a problem with this, then go suck the barrel of a Glock.</td>\n",
       "      <td>test</td>\n",
       "      <td>2016-11-01 16:53:33.561631+00</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149218</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.592105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5410943</td>\n",
       "      <td>Tucker and Paul are both total bad ass mofo's.</td>\n",
       "      <td>train</td>\n",
       "      <td>2017-06-14 05:08:21.997315+00</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>344096</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.337500</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.487500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  \\\n",
       "0  1083994   \n",
       "1   650904   \n",
       "2  5902188   \n",
       "3  7084460   \n",
       "4  5410943   \n",
       "\n",
       "                                                                                                                                                                                   comment_text  \\\n",
       "0  He got his money... now he lies in wait till after the election in 2 yrs.... dirty politicians need to be afraid of Tar and feathers again... but they aren't and so the people get screwed.   \n",
       "1                                                                                                                              Mad dog will surely put the liberals in mental hospitals. Boorah   \n",
       "2                                                                        And Trump continues his lifelong cowardice by not making this announcement himself.\\n\\nWhat an awful human being .....   \n",
       "3                                                        \"while arresting a man for resisting arrest\".\\n\\nIf you cop-suckers can't see a problem with this, then go suck the barrel of a Glock.   \n",
       "4                                                                                                                                                Tucker and Paul are both total bad ass mofo's.   \n",
       "\n",
       "   split                   created_date  publication_id  parent_id  \\\n",
       "0  train  2017-03-06 15:21:53.675241+00              21        NaN   \n",
       "1  train  2016-12-02 16:44:21.329535+00              21        NaN   \n",
       "2  train  2017-09-05 19:05:32.341360+00              55        NaN   \n",
       "3   test  2016-11-01 16:53:33.561631+00              13        NaN   \n",
       "4  train  2017-06-14 05:08:21.997315+00              21        NaN   \n",
       "\n",
       "   article_id    rating  funny  wow  sad  likes  disagree  toxicity  \\\n",
       "0      317120  approved      0    0    0      2         0  0.373134   \n",
       "1      154086  approved      0    0    1      2         0  0.605263   \n",
       "2      374342  approved      1    0    2      3         7  0.666667   \n",
       "3      149218  approved      0    0    0      0         0  0.815789   \n",
       "4      344096  approved      0    0    0      1         0  0.550000   \n",
       "\n",
       "   severe_toxicity   obscene  sexual_explicit  identity_attack    insult  \\\n",
       "0         0.044776  0.089552         0.014925         0.000000  0.343284   \n",
       "1         0.013158  0.065789         0.013158         0.092105  0.565789   \n",
       "2         0.015873  0.031746         0.000000         0.047619  0.666667   \n",
       "3         0.065789  0.552632         0.592105         0.000000  0.684211   \n",
       "4         0.037500  0.337500         0.275000         0.037500  0.487500   \n",
       "\n",
       "     threat  male  female  transgender  other_gender  heterosexual  \\\n",
       "0  0.014925   NaN     NaN          NaN           NaN           NaN   \n",
       "1  0.065789   NaN     NaN          NaN           NaN           NaN   \n",
       "2  0.000000   NaN     NaN          NaN           NaN           NaN   \n",
       "3  0.105263   NaN     NaN          NaN           NaN           NaN   \n",
       "4  0.000000   NaN     NaN          NaN           NaN           NaN   \n",
       "\n",
       "   homosexual_gay_or_lesbian  bisexual  other_sexual_orientation  christian  \\\n",
       "0                        NaN       NaN                       NaN        NaN   \n",
       "1                        NaN       NaN                       NaN        NaN   \n",
       "2                        NaN       NaN                       NaN        NaN   \n",
       "3                        NaN       NaN                       NaN        NaN   \n",
       "4                        NaN       NaN                       NaN        NaN   \n",
       "\n",
       "   jewish  muslim  hindu  buddhist  atheist  other_religion  black  white  \\\n",
       "0     NaN     NaN    NaN       NaN      NaN             NaN    NaN    NaN   \n",
       "1     NaN     NaN    NaN       NaN      NaN             NaN    NaN    NaN   \n",
       "2     NaN     NaN    NaN       NaN      NaN             NaN    NaN    NaN   \n",
       "3     NaN     NaN    NaN       NaN      NaN             NaN    NaN    NaN   \n",
       "4     NaN     NaN    NaN       NaN      NaN             NaN    NaN    NaN   \n",
       "\n",
       "   asian  latino  other_race_or_ethnicity  physical_disability  \\\n",
       "0    NaN     NaN                      NaN                  NaN   \n",
       "1    NaN     NaN                      NaN                  NaN   \n",
       "2    NaN     NaN                      NaN                  NaN   \n",
       "3    NaN     NaN                      NaN                  NaN   \n",
       "4    NaN     NaN                      NaN                  NaN   \n",
       "\n",
       "   intellectual_or_learning_disability  psychiatric_or_mental_illness  \\\n",
       "0                                  NaN                            NaN   \n",
       "1                                  NaN                            NaN   \n",
       "2                                  NaN                            NaN   \n",
       "3                                  NaN                            NaN   \n",
       "4                                  NaN                            NaN   \n",
       "\n",
       "   other_disability  identity_annotator_count  toxicity_annotator_count  \n",
       "0               NaN                         0                        67  \n",
       "1               NaN                         0                        76  \n",
       "2               NaN                         0                        63  \n",
       "3               NaN                         0                        76  \n",
       "4               NaN                         0                        80  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = pd.read_csv('../data/toxic_data.csv', chunksize=100000)\n",
    "df = pd.concat(chunks)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17df83e7-bc39-4c5b-81f0-68bf155d097a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comment_text'] = df['comment_text'].fillna(\"\")\n",
    "identity_columns = ['male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish', 'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "for col in identity_columns + ['toxicity']:\n",
    "    df.loc[:, col] = np.where(df[col] >= 0.5, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66e3ed1e-38cc-4da9-bca6-494ae5ff21c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1804875, 46), (194641, 46))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = df[df['split'] == 'train']\n",
    "test_df = df[df['split'] != 'train']\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c45d26f-d1c1-4b93-94d3-dc764661885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = train_df.sample(N_SAMPLES, random_state=SEED, ignore_index=True)\n",
    "train_text, val_text, train_label, val_label = train_test_split(sample['comment_text'], sample['toxicity'], test_size=0.2, random_state=SEED)\n",
    "test_text, test_label = test_df['comment_text'], test_df['toxicity']\n",
    "\n",
    "train_label = torch.tensor(train_label.values, dtype=torch.float32).to(device)\n",
    "val_label = torch.tensor(val_label.values, dtype=torch.float32).to(device) \n",
    "test_label = torch.tensor(test_label.values, dtype=torch.float32).to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccd05565-defd-4178-b086-667ef9cf4a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800000,), (194641,), 800000, 194641, (200000,), 200000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text.shape, test_text.shape, len(train_label), len(test_label), val_text.shape, len(val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a16e6fed-323a-4563-a2ce-3ba57e1c7d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "counter = Counter()\n",
    "for line in train_text:\n",
    "    counter.update(tokenizer(line))\n",
    "    \n",
    "# Create a vocabulary with words seen at least 3 (min_freq) times\n",
    "vocab = torchtext.vocab.vocab(counter, min_freq=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7306873-fe3a-4899-bf58-8cdbfa9ccea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the unknown token and use it by default for unknown words\n",
    "unk_token = '<unk>'\n",
    "# vocab.insert_token(unk_token, 0)\n",
    "vocab.set_default_index(0)\n",
    "\n",
    "# Add the pad token Explanation https://huggingface.co/docs/transformers/pad_truncation\n",
    "pad_token = '<pad>'\n",
    "vocab.insert_token(pad_token, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9e1103d-bc7b-4cc5-9b20-86e71e2f0081",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_transform_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8593d17c-6ebe-4e54-a0f9-ab97ce4cde64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before transform:\n",
      "A great article about a very important topic. Hopefully this program can clean up the air in these homes and improve the health of all of the occupants.\n",
      "After transform:\n",
      "[17, 731, 467, 32, 17, 104, 644, 1191, 14, 1515, 50, 3055, 168, 138, 22, 7, 143, 24, 303, 4495, 41, 206, 7, 1267, 11, 111, 11, 7, 10967, 14]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before transform:\\n{train_text.iloc[1666]}\")\n",
    "print(f\"After transform:\\n{text_transform_pipeline(train_text.iloc[1666])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6b31850-a51f-4b7a-99c2-2d9a3ee9710a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformText(text_list, max_len):\n",
    "    # Transform the text\n",
    "    transformed_data = [text_transform_pipeline(text)[:max_len] for text in text_list]\n",
    "\n",
    "    # Pad zeros if the text is shoter than max_len\n",
    "    for data in transformed_data:\n",
    "        data[len(data) : max_len] = np.ones(max_len - len(data))\n",
    "\n",
    "    return torch.tensor(transformed_data, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6688220c-5cf2-4a7f-b5f0-4270c4e15951",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 100\n",
    "batch_size = 128\n",
    "\n",
    "# Pass transformed and padded data to dataset\n",
    "# Create data loaders\n",
    "train_dataset = TensorDataset(\n",
    "    transformText(train_text, max_len), train_label\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "val_dataset = TensorDataset(transformText(val_text, max_len), val_label)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "test_dataset = TensorDataset(transformText(test_text, max_len), test_label)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b282d16b-6544-49d1-ac3c-bb4c63116f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pretrained Word Embeddings ====> GloVe, FastText, CharNGram\n",
    "\n",
    "glove = GloVe(name=\"6B\", dim=300)\n",
    "embedding_matrix = glove.get_vecs_by_tokens(vocab.get_itos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a52cb61-d1f1-40d5-9c00-ebf234219d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100185, 300])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f40b77b5-53f6-4a7b-9cef-1f39eb92c4bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100185"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size of the state vectors\n",
    "hidden_size = 128\n",
    "# General NN training parameters\n",
    "learning_rate = 0.001\n",
    "epochs = 5\n",
    "\n",
    "# Embedding vector and vocabulary sizes\n",
    "embed_size = 300  # glove.6B.300d.txt\n",
    "vocab_size = len(vocab.get_itos())\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5abaf7bc-7ab0-4c62-bed6-179a3797f838",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialDropout(nn.Dropout2d):\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(2)    # (N, T, 1, K)\n",
    "        x = x.permute(0, 3, 2, 1)  # (N, K, 1, T)\n",
    "        x = super(SpatialDropout, self).forward(x)  # (N, K, 1, T), some features are masked\n",
    "        x = x.permute(0, 3, 2, 1)  # (N, T, 1, K)\n",
    "        x = x.squeeze(2)  # (N, T, K)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        self.embedding_dropout = SpatialDropout(0.5)\n",
    "        self.lstm = nn.LSTM(\n",
    "            embed_size, hidden_size, num_layers=num_layers\n",
    "        )\n",
    "        self.linear = nn.Linear(hidden_size*max_len, 1)\n",
    "        self.act = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeddings = self.embedding(inputs)\n",
    "        embeddings = self.embedding_dropout(embeddings)\n",
    "        # Call LSTM layer\n",
    "        outputs, _ = self.lstm(embeddings)\n",
    "        # Use the output of each time step\n",
    "        # Send it all together to the linear layer\n",
    "        outs = self.linear(outputs.reshape(outputs.shape[0], -1))\n",
    "        return self.act(outs)\n",
    "    \n",
    "model = Net(vocab_size, embed_size, hidden_size, num_layers=5)\n",
    "\n",
    "# Initialize the weights\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "    if type(m) == nn.LSTM:\n",
    "        for param in m._flat_weights_names:\n",
    "            if \"weight\" in param:\n",
    "                nn.init.xavier_uniform_(m._parameters[param])\n",
    "                \n",
    "# We set the embedding layer's parameters from GloVe\n",
    "model.embedding.weight.data.copy_(embedding_matrix)\n",
    "# We set the embedding layer's parameters from GloVe\n",
    "# We won't change/train the embedding layer\n",
    "model.embedding.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b293191-b215-4cfe-b896-ed9c89e2964e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting our trainer\n",
    "trainer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# We will use Binary Cross-entropy loss\n",
    "# reduction=\"sum\" sums the losses for given output and target\n",
    "cross_ent_loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6fd4e95e-c03d-469c-a2ff-57bbd3cdae0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Train_loss 0.0015387570012314244. Validation_loss 0.0013855114074796439. Seconds 189.0780258178711\n",
      "Epoch 1. Train_loss 0.0013285043846489862. Validation_loss 0.0013274204105511308. Seconds 198.3671679496765\n",
      "Epoch 2. Train_loss 0.0012960864729993046. Validation_loss 0.00130025836372748. Seconds 190.18723678588867\n",
      "Epoch 3. Train_loss 0.001277551847025752. Validation_loss 0.0012944579164125025. Seconds 189.37853121757507\n",
      "Epoch 4. Train_loss 0.0012663778361305595. Validation_loss 0.0012877526112645866. Seconds 199.97514963150024\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Get the compute device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.apply(init_weights)\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    training_loss = 0\n",
    "    val_loss = 0\n",
    "    # Training loop, train the network\n",
    "    for data, target in train_loader:\n",
    "        trainer.zero_grad()\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(data)\n",
    "        L = cross_ent_loss(output.squeeze(1), target)\n",
    "        training_loss += L.item()\n",
    "        L.backward()\n",
    "        trainer.step()\n",
    "\n",
    "    # Validate the network, no training (no weight update)\n",
    "    for data, target in val_loader:\n",
    "        val_predictions = model(data.to(device))\n",
    "        L = cross_ent_loss(val_predictions.squeeze(1), target.to(device))\n",
    "        val_loss += L.item()\n",
    "\n",
    "    # Let's take the average losses\n",
    "    training_loss = training_loss / len(train_label)\n",
    "    val_loss = val_loss / len(val_label)\n",
    "    \n",
    "    train_losses.append(training_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    end = time.time()\n",
    "    print(\n",
    "        f\"Epoch {epoch}. Train_loss {training_loss}. Validation_loss {val_loss}. Seconds {end-start}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4672556a-20da-4c21-9f30-5e58c1e975f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label=\"Training Loss\")\n",
    "plt.plot(val_losses, label=\"Validation Loss\")\n",
    "plt.title(\"Loss values\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69935460-6a80-4be9-bad9-a36a1d8bbedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1521/1521 [00:15<00:00, 95.15it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_predictions = []\n",
    "for data, target in tqdm(test_loader):\n",
    "    test_preds = model(data.to(device))\n",
    "    test_predictions.extend(\n",
    "        [np.rint(test_pred)[0] for test_pred in test_preds.detach().cpu().numpy()]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a32e0dac-1c08-45a4-b113-5174e50efe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(test_predictions), len(test_predictions)\n",
    "oof_name = 'predicted_target'\n",
    "test_df[oof_name] = test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2fc61c64-0eb8-428e-a2fa-73da9096e688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subgroup</th>\n",
       "      <th>subgroup_size</th>\n",
       "      <th>subgroup_auc</th>\n",
       "      <th>bpsn_auc</th>\n",
       "      <th>bnsp_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jewish</td>\n",
       "      <td>835</td>\n",
       "      <td>0.615443</td>\n",
       "      <td>0.680930</td>\n",
       "      <td>0.631395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>homosexual_gay_or_lesbian</td>\n",
       "      <td>1065</td>\n",
       "      <td>0.616474</td>\n",
       "      <td>0.659520</td>\n",
       "      <td>0.654160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>muslim</td>\n",
       "      <td>2040</td>\n",
       "      <td>0.624269</td>\n",
       "      <td>0.680580</td>\n",
       "      <td>0.641838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>black</td>\n",
       "      <td>1519</td>\n",
       "      <td>0.629743</td>\n",
       "      <td>0.651113</td>\n",
       "      <td>0.675822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>christian</td>\n",
       "      <td>4226</td>\n",
       "      <td>0.639755</td>\n",
       "      <td>0.695152</td>\n",
       "      <td>0.642389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>white</td>\n",
       "      <td>2452</td>\n",
       "      <td>0.645875</td>\n",
       "      <td>0.659064</td>\n",
       "      <td>0.684043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>psychiatric_or_mental_illness</td>\n",
       "      <td>511</td>\n",
       "      <td>0.651642</td>\n",
       "      <td>0.665642</td>\n",
       "      <td>0.682401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>5155</td>\n",
       "      <td>0.664442</td>\n",
       "      <td>0.686661</td>\n",
       "      <td>0.675280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>4386</td>\n",
       "      <td>0.677786</td>\n",
       "      <td>0.682046</td>\n",
       "      <td>0.692464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        subgroup  subgroup_size  subgroup_auc  bpsn_auc  \\\n",
       "4                         jewish            835      0.615443  0.680930   \n",
       "2      homosexual_gay_or_lesbian           1065      0.616474  0.659520   \n",
       "5                         muslim           2040      0.624269  0.680580   \n",
       "6                          black           1519      0.629743  0.651113   \n",
       "3                      christian           4226      0.639755  0.695152   \n",
       "7                          white           2452      0.645875  0.659064   \n",
       "8  psychiatric_or_mental_illness            511      0.651642  0.665642   \n",
       "1                         female           5155      0.664442  0.686661   \n",
       "0                           male           4386      0.677786  0.682046   \n",
       "\n",
       "   bnsp_auc  \n",
       "4  0.631395  \n",
       "2  0.654160  \n",
       "5  0.641838  \n",
       "6  0.675822  \n",
       "3  0.642389  \n",
       "7  0.684043  \n",
       "8  0.682401  \n",
       "1  0.675280  \n",
       "0  0.692464  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SUBGROUP_AUC = 'subgroup_auc'\n",
    "BPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\n",
    "BNSP_AUC = 'bnsp_auc'  # stands for background negative, subgroup positive\n",
    "\n",
    "def compute_auc(y_true, y_pred):\n",
    "    try:\n",
    "        return roc_auc_score(y_true, y_pred)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "def compute_subgroup_auc(df, subgroup, label, oof_name):\n",
    "    subgroup_examples = df[df[subgroup]]\n",
    "    return compute_auc(subgroup_examples[label], subgroup_examples[oof_name])\n",
    "\n",
    "def compute_bpsn_auc(df, subgroup, label, oof_name):\n",
    "    \"\"\"Computes the AUC of the within-subgroup negative examples and the background positive examples.\"\"\"\n",
    "    subgroup_negative_examples = df[df[subgroup] & ~df[label]]\n",
    "    non_subgroup_positive_examples = df[~df[subgroup] & df[label]]\n",
    "    examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n",
    "    return compute_auc(examples[label], examples[oof_name])\n",
    "\n",
    "def compute_bnsp_auc(df, subgroup, label, oof_name):\n",
    "    \"\"\"Computes the AUC of the within-subgroup positive examples and the background negative examples.\"\"\"\n",
    "    subgroup_positive_examples = df[df[subgroup] & df[label]]\n",
    "    non_subgroup_negative_examples = df[~df[subgroup] & ~df[label]]\n",
    "    examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n",
    "    return compute_auc(examples[label], examples[oof_name])\n",
    "\n",
    "def compute_bias_metrics_for_model(dataset,\n",
    "                                   subgroups,\n",
    "                                   model,\n",
    "                                   label_col,\n",
    "                                   include_asegs=False):\n",
    "    \"\"\"Computes per-subgroup metrics for all subgroups and one model.\"\"\"\n",
    "    records = []\n",
    "    for subgroup in subgroups:\n",
    "        record = {\n",
    "            'subgroup': subgroup,\n",
    "            'subgroup_size': len(dataset[dataset[subgroup]])\n",
    "        }\n",
    "        record[SUBGROUP_AUC] = compute_subgroup_auc(dataset, subgroup, label_col, model)\n",
    "        record[BPSN_AUC] = compute_bpsn_auc(dataset, subgroup, label_col, model)\n",
    "        record[BNSP_AUC] = compute_bnsp_auc(dataset, subgroup, label_col, model)\n",
    "        records.append(record)\n",
    "    return pd.DataFrame(records).sort_values('subgroup_auc', ascending=True)\n",
    "bias_metrics_df = compute_bias_metrics_for_model(test_df, identity_columns, oof_name, 'toxicity')\n",
    "bias_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f32180a1-c18b-459e-ada0-61dc1f4df5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL SCORE IS 0.6674767492376529\n"
     ]
    }
   ],
   "source": [
    "def calculate_overall_auc(df, oof_name):\n",
    "    true_labels = df['toxicity']\n",
    "    predicted_labels = df[oof_name]\n",
    "    return roc_auc_score(true_labels, predicted_labels)\n",
    "\n",
    "def power_mean(series, p):\n",
    "    total = sum(np.power(series, p))\n",
    "    return np.power(total / len(series), 1 / p)\n",
    "\n",
    "def get_final_metric(bias_df, overall_auc, POWER=-5, OVERALL_MODEL_WEIGHT=0.25):\n",
    "    bias_score = np.average([\n",
    "        power_mean(bias_df[SUBGROUP_AUC], POWER),\n",
    "        power_mean(bias_df[BPSN_AUC], POWER),\n",
    "        power_mean(bias_df[BNSP_AUC], POWER)\n",
    "    ])\n",
    "    return (OVERALL_MODEL_WEIGHT * overall_auc) + ((1 - OVERALL_MODEL_WEIGHT) * bias_score)\n",
    "FINAL_SCORE = get_final_metric(bias_metrics_df, calculate_overall_auc(test_df, oof_name))\n",
    "print(f\"FINAL SCORE IS {FINAL_SCORE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad82282-3533-49fe-a9f4-42cba106b229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf4e32c-f165-4b85-b615-cc96ca2bd578",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p37",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
