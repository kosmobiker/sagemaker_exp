{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0823c3e2-70ac-4074-97f4-584c732a675c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import awswrangler as wr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "SEED = 1234\n",
    "N_SAMPLES = 100_000\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import gensim.downloader as api\n",
    "from gensim import corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim import models\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.matutils import corpus2dense, corpus2csc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "pd.options.mode.chained_assignment = None\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7ed2fb4-d4d5-45ff-a695-aca77c1273a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>split</th>\n",
       "      <th>created_date</th>\n",
       "      <th>publication_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>transgender</th>\n",
       "      <th>other_gender</th>\n",
       "      <th>heterosexual</th>\n",
       "      <th>homosexual_gay_or_lesbian</th>\n",
       "      <th>bisexual</th>\n",
       "      <th>other_sexual_orientation</th>\n",
       "      <th>christian</th>\n",
       "      <th>jewish</th>\n",
       "      <th>muslim</th>\n",
       "      <th>hindu</th>\n",
       "      <th>buddhist</th>\n",
       "      <th>atheist</th>\n",
       "      <th>other_religion</th>\n",
       "      <th>black</th>\n",
       "      <th>white</th>\n",
       "      <th>asian</th>\n",
       "      <th>latino</th>\n",
       "      <th>other_race_or_ethnicity</th>\n",
       "      <th>physical_disability</th>\n",
       "      <th>intellectual_or_learning_disability</th>\n",
       "      <th>psychiatric_or_mental_illness</th>\n",
       "      <th>other_disability</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1083994</td>\n",
       "      <td>He got his money... now he lies in wait till after the election in 2 yrs.... dirty politicians need to be afraid of Tar and feathers again... but they aren't and so the people get screwed.</td>\n",
       "      <td>train</td>\n",
       "      <td>2017-03-06 15:21:53.675241+00</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>317120</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.373134</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.343284</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>650904</td>\n",
       "      <td>Mad dog will surely put the liberals in mental hospitals. Boorah</td>\n",
       "      <td>train</td>\n",
       "      <td>2016-12-02 16:44:21.329535+00</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154086</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.092105</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5902188</td>\n",
       "      <td>And Trump continues his lifelong cowardice by not making this announcement himself.\\n\\nWhat an awful human being .....</td>\n",
       "      <td>train</td>\n",
       "      <td>2017-09-05 19:05:32.341360+00</td>\n",
       "      <td>55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374342</td>\n",
       "      <td>approved</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7084460</td>\n",
       "      <td>\"while arresting a man for resisting arrest\".\\n\\nIf you cop-suckers can't see a problem with this, then go suck the barrel of a Glock.</td>\n",
       "      <td>test</td>\n",
       "      <td>2016-11-01 16:53:33.561631+00</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149218</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.592105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5410943</td>\n",
       "      <td>Tucker and Paul are both total bad ass mofo's.</td>\n",
       "      <td>train</td>\n",
       "      <td>2017-06-14 05:08:21.997315+00</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>344096</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.337500</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.487500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  \\\n",
       "0  1083994   \n",
       "1   650904   \n",
       "2  5902188   \n",
       "3  7084460   \n",
       "4  5410943   \n",
       "\n",
       "                                                                                                                                                                                   comment_text  \\\n",
       "0  He got his money... now he lies in wait till after the election in 2 yrs.... dirty politicians need to be afraid of Tar and feathers again... but they aren't and so the people get screwed.   \n",
       "1                                                                                                                              Mad dog will surely put the liberals in mental hospitals. Boorah   \n",
       "2                                                                        And Trump continues his lifelong cowardice by not making this announcement himself.\\n\\nWhat an awful human being .....   \n",
       "3                                                        \"while arresting a man for resisting arrest\".\\n\\nIf you cop-suckers can't see a problem with this, then go suck the barrel of a Glock.   \n",
       "4                                                                                                                                                Tucker and Paul are both total bad ass mofo's.   \n",
       "\n",
       "   split                   created_date  publication_id  parent_id  \\\n",
       "0  train  2017-03-06 15:21:53.675241+00              21        NaN   \n",
       "1  train  2016-12-02 16:44:21.329535+00              21        NaN   \n",
       "2  train  2017-09-05 19:05:32.341360+00              55        NaN   \n",
       "3   test  2016-11-01 16:53:33.561631+00              13        NaN   \n",
       "4  train  2017-06-14 05:08:21.997315+00              21        NaN   \n",
       "\n",
       "   article_id    rating  funny  wow  sad  likes  disagree  toxicity  \\\n",
       "0      317120  approved      0    0    0      2         0  0.373134   \n",
       "1      154086  approved      0    0    1      2         0  0.605263   \n",
       "2      374342  approved      1    0    2      3         7  0.666667   \n",
       "3      149218  approved      0    0    0      0         0  0.815789   \n",
       "4      344096  approved      0    0    0      1         0  0.550000   \n",
       "\n",
       "   severe_toxicity   obscene  sexual_explicit  identity_attack    insult  \\\n",
       "0         0.044776  0.089552         0.014925         0.000000  0.343284   \n",
       "1         0.013158  0.065789         0.013158         0.092105  0.565789   \n",
       "2         0.015873  0.031746         0.000000         0.047619  0.666667   \n",
       "3         0.065789  0.552632         0.592105         0.000000  0.684211   \n",
       "4         0.037500  0.337500         0.275000         0.037500  0.487500   \n",
       "\n",
       "     threat  male  female  transgender  other_gender  heterosexual  \\\n",
       "0  0.014925   NaN     NaN          NaN           NaN           NaN   \n",
       "1  0.065789   NaN     NaN          NaN           NaN           NaN   \n",
       "2  0.000000   NaN     NaN          NaN           NaN           NaN   \n",
       "3  0.105263   NaN     NaN          NaN           NaN           NaN   \n",
       "4  0.000000   NaN     NaN          NaN           NaN           NaN   \n",
       "\n",
       "   homosexual_gay_or_lesbian  bisexual  other_sexual_orientation  christian  \\\n",
       "0                        NaN       NaN                       NaN        NaN   \n",
       "1                        NaN       NaN                       NaN        NaN   \n",
       "2                        NaN       NaN                       NaN        NaN   \n",
       "3                        NaN       NaN                       NaN        NaN   \n",
       "4                        NaN       NaN                       NaN        NaN   \n",
       "\n",
       "   jewish  muslim  hindu  buddhist  atheist  other_religion  black  white  \\\n",
       "0     NaN     NaN    NaN       NaN      NaN             NaN    NaN    NaN   \n",
       "1     NaN     NaN    NaN       NaN      NaN             NaN    NaN    NaN   \n",
       "2     NaN     NaN    NaN       NaN      NaN             NaN    NaN    NaN   \n",
       "3     NaN     NaN    NaN       NaN      NaN             NaN    NaN    NaN   \n",
       "4     NaN     NaN    NaN       NaN      NaN             NaN    NaN    NaN   \n",
       "\n",
       "   asian  latino  other_race_or_ethnicity  physical_disability  \\\n",
       "0    NaN     NaN                      NaN                  NaN   \n",
       "1    NaN     NaN                      NaN                  NaN   \n",
       "2    NaN     NaN                      NaN                  NaN   \n",
       "3    NaN     NaN                      NaN                  NaN   \n",
       "4    NaN     NaN                      NaN                  NaN   \n",
       "\n",
       "   intellectual_or_learning_disability  psychiatric_or_mental_illness  \\\n",
       "0                                  NaN                            NaN   \n",
       "1                                  NaN                            NaN   \n",
       "2                                  NaN                            NaN   \n",
       "3                                  NaN                            NaN   \n",
       "4                                  NaN                            NaN   \n",
       "\n",
       "   other_disability  identity_annotator_count  toxicity_annotator_count  \n",
       "0               NaN                         0                        67  \n",
       "1               NaN                         0                        76  \n",
       "2               NaN                         0                        63  \n",
       "3               NaN                         0                        76  \n",
       "4               NaN                         0                        80  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = pd.read_csv('../data/toxic_data.csv', chunksize=100000)\n",
    "df = pd.concat(chunks)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "442b5002-7e2d-4124-8bb4-8568c4bfd0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comment_text'] = df['comment_text'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "290a5ce3-4df0-4b84-a6bd-779a0ebfd052",
   "metadata": {},
   "outputs": [],
   "source": [
    "identity_columns = ['male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish', 'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "for col in identity_columns + ['toxicity']:\n",
    "    df.loc[:, col] = np.where(df[col] >= 0.5, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0dd1524-0fae-4fb6-b77e-37a8e50c7f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df['split'] == 'train']\n",
    "test_df = df[df['split'] != 'train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d42fd528-f83c-4d0f-ba04-16c4579d4681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1804875, 46), (194641, 46))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b4888d6-0021-4f79-bced-db2614cb943c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df\n",
    "# sample = train_df.sample(N_SAMPLES, random_state=SEED, ignore_index=True)\n",
    "train_text, val_text, train_label, val_label = train_test_split(sample['comment_text'], sample['toxicity'], test_size=0.2, random_state=SEED)\n",
    "# train_text, train_label = sample['comment_text'], sample['toxicity']\n",
    "test_text, test_label = test_df['comment_text'], test_df['toxicity']\n",
    "\n",
    "# train_label = train_label.astype('int').to_numpy()\n",
    "# val_label = val_label.astype('int').to_numpy()\n",
    "# test_label = test_label.astype('int').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c3f9995-0cc8-4158-b504-9128c3042eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1599612,), (399904,), (194641,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text.shape, val_text.shape, test_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a24bdaa8-c781-4f01-9111-1f743572c62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "misspell_dict = {\"aren't\": \"are not\", \"can't\": \"cannot\", \"couldn't\": \"could not\",\n",
    "                 \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\",\n",
    "                 \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                 \"he'd\": \"he would\", \"he'll\": \"he will\", \"he's\": \"he is\",\n",
    "                 \"i'd\": \"I had\", \"i'll\": \"I will\", \"i'm\": \"I am\", \"isn't\": \"is not\",\n",
    "                 \"it's\": \"it is\", \"it'll\": \"it will\", \"i've\": \"I have\", \"let's\": \"let us\",\n",
    "                 \"mightn't\": \"might not\", \"mustn't\": \"must not\", \"shan't\": \"shall not\",\n",
    "                 \"she'd\": \"she would\", \"she'll\": \"she will\", \"she's\": \"she is\",\n",
    "                 \"shouldn't\": \"should not\", \"that's\": \"that is\", \"there's\": \"there is\",\n",
    "                 \"they'd\": \"they would\", \"they'll\": \"they will\", \"they're\": \"they are\",\n",
    "                 \"they've\": \"they have\", \"we'd\": \"we would\", \"we're\": \"we are\",\n",
    "                 \"weren't\": \"were not\", \"we've\": \"we have\", \"what'll\": \"what will\",\n",
    "                 \"what're\": \"what are\", \"what's\": \"what is\", \"what've\": \"what have\",\n",
    "                 \"where's\": \"where is\", \"who'd\": \"who would\", \"who'll\": \"who will\",\n",
    "                 \"who're\": \"who are\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                 \"won't\": \"will not\", \"wouldn't\": \"would not\", \"you'd\": \"you would\",\n",
    "                 \"you'll\": \"you will\", \"you're\": \"you are\", \"you've\": \"you have\",\n",
    "                 \"'re\": \" are\", \"wasn't\": \"was not\", \"we'll\": \" will\", \"tryin'\": \"trying\"}\n",
    "\n",
    "\n",
    "def _get_misspell(misspell_dict):\n",
    "    misspell_re = re.compile('(%s)' % '|'.join(misspell_dict.keys()))\n",
    "    return misspell_dict, misspell_re\n",
    "\n",
    "\n",
    "def replace_typical_misspell(text):\n",
    "    misspellings, misspellings_re = _get_misspell(misspell_dict)\n",
    "\n",
    "    def replace(match):\n",
    "        return misspellings[match.group(0)]\n",
    "\n",
    "    return misspellings_re.sub(replace, text)\n",
    "    \n",
    "\n",
    "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']',\n",
    "          '>', '%', '=', '#', '*', '+', '\\\\', '•', '~', '@', '£', '·', '_', '{', '}', '©', '^',\n",
    "          '®', '`', '<', '→', '°', '€', '™', '›', '♥', '←', '×', '§', '″', '′', 'Â', '█',\n",
    "          '½', 'à', '…', '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶',\n",
    "          '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '▒', '：', '¼',\n",
    "          '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲',\n",
    "          'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', '∙', '）', '↓', '、', '│', '（', '»', '，', '♪',\n",
    "          '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√']\n",
    "\n",
    "\n",
    "def clean_text(x):\n",
    "    x = str(x)\n",
    "    for punct in puncts + list(string.punctuation):\n",
    "        if punct in x:\n",
    "            x = x.replace(punct, f' {punct} ')\n",
    "    return x\n",
    "\n",
    "\n",
    "def clean_numbers(x):\n",
    "    return re.sub('\\d+', ' ', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a2356c5-1f10-438a-81c9-b4251edb8e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean misspellings\n",
    "train_text = train_text.apply(replace_typical_misspell)\n",
    "val_text = val_text.apply(replace_typical_misspell)\n",
    "test_text = test_text.apply(replace_typical_misspell)\n",
    "\n",
    "# clean the text\n",
    "train_text = train_text.apply(clean_text)\n",
    "val_text = val_text.apply(replace_typical_misspell)\n",
    "test_text = test_text.apply(clean_text)\n",
    "\n",
    "# clean numbers\n",
    "train_text = train_text.apply(clean_numbers)\n",
    "val_text = val_text.apply(replace_typical_misspell)\n",
    "test_text = test_text.apply(clean_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50851429-f4a8-4003-af45-d3111809c1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_preproc(text):\n",
    "    for line in text:\n",
    "        yield simple_preprocess(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3383d913-4e0c-44c9-a97b-449d8febcfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_lists = list(map(lambda x: simple_preprocess(x), train_text))\n",
    "# test_lists = list(map(lambda x: simple_preprocess(x), test_text))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85e0c51a-b506-4b2d-9356-61fc069d664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_lists = [simple_preprocess(doc) for doc in tqdm(train_text)]\n",
    "# # val_lists = [simple_preprocess(doc) for doc in val_text]\n",
    "# test_lists = [simple_preprocess(doc) for doc in tqdm(test_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b0ef817-d21c-4d89-9fa1-a9bf982ccd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1599612it [03:33, 7492.26it/s]\n",
      "399904it [00:38, 10458.24it/s]\n",
      "194641it [00:18, 10774.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create the Dictionary and Corpus\n",
    "dictionary = corpora.Dictionary()\n",
    "\n",
    "#allow_update=True - add new words to dictionary\n",
    "bow_train = [dictionary.doc2bow(doc, allow_update=True) for doc in tqdm(simple_preproc(train_text))]\n",
    "bow_val = [dictionary.doc2bow(doc, allow_update=False) for doc in tqdm(simple_preproc(val_text))]\n",
    "bow_test = [dictionary.doc2bow(doc, allow_update=False) for doc in tqdm(simple_preproc(test_text))] \n",
    "\n",
    "dictionary.save(\"my_dictionary_full\")\n",
    "loaded_dict = corpora.Dictionary.load(\"my_dictionary_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35180f8c-dcf9-44c5-be28-a839b0973609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of docs is 1599612, there are 261552 words in dictionary\n"
     ]
    }
   ],
   "source": [
    "num_docs = dictionary.num_docs\n",
    "num_terms = len(dictionary.keys())\n",
    "print(f\"Number of docs is {num_docs}, there are {num_terms} words in dictionary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "352c3f94-7018-42ba-bc90-8e9b6b91cc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = models.TfidfModel(bow_train, dictionary=loaded_dict)\n",
    "train_tfidf = tfidf[bow_train]\n",
    "val_tfidf = tfidf[bow_val]\n",
    "test_tfidf = tfidf[bow_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "655617b8-dd75-4793-b442-6c36189068ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidf_sparse = corpus2csc(train_tfidf, num_terms=num_terms, num_docs=num_docs).T\n",
    "val_tfidf_sparse = corpus2csc(val_tfidf, num_terms=num_terms).T\n",
    "test_tfidf_sparse = corpus2csc(test_tfidf, num_terms=num_terms).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86262f5b-55e3-4cac-bebf-0518cf8be1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM memory % used: 74.04\n"
     ]
    }
   ],
   "source": [
    "# Getting all memory using os.popen()\n",
    "total_memory, used_memory, free_memory = map(\n",
    "    int, os.popen('free -t -m').readlines()[-1].split()[1:])\n",
    "  \n",
    "# Memory usage\n",
    "print(\"RAM memory % used:\", round((used_memory/total_memory) * 100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57ee7d62-2e07-46b6-9aa3-ec7197d35659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 29s, sys: 2min 26s, total: 6min 55s\n",
      "Wall time: 2min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(train_tfidf_sparse, train_label)\n",
    "oof_name = 'predicted_target'\n",
    "test_df[oof_name] = logreg.predict_proba(test_tfidf_sparse)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e454ec7-37a8-457d-8728-da3035b72808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subgroup</th>\n",
       "      <th>subgroup_size</th>\n",
       "      <th>subgroup_auc</th>\n",
       "      <th>bpsn_auc</th>\n",
       "      <th>bnsp_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>black</td>\n",
       "      <td>1519</td>\n",
       "      <td>0.812314</td>\n",
       "      <td>0.785562</td>\n",
       "      <td>0.973499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>homosexual_gay_or_lesbian</td>\n",
       "      <td>1065</td>\n",
       "      <td>0.814605</td>\n",
       "      <td>0.820933</td>\n",
       "      <td>0.962834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>white</td>\n",
       "      <td>2452</td>\n",
       "      <td>0.835842</td>\n",
       "      <td>0.803607</td>\n",
       "      <td>0.974137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>muslim</td>\n",
       "      <td>2040</td>\n",
       "      <td>0.840519</td>\n",
       "      <td>0.844202</td>\n",
       "      <td>0.963600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jewish</td>\n",
       "      <td>835</td>\n",
       "      <td>0.881251</td>\n",
       "      <td>0.881476</td>\n",
       "      <td>0.964172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>psychiatric_or_mental_illness</td>\n",
       "      <td>511</td>\n",
       "      <td>0.902131</td>\n",
       "      <td>0.871045</td>\n",
       "      <td>0.970198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>4386</td>\n",
       "      <td>0.913665</td>\n",
       "      <td>0.902575</td>\n",
       "      <td>0.966827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>5155</td>\n",
       "      <td>0.918091</td>\n",
       "      <td>0.914620</td>\n",
       "      <td>0.963152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>christian</td>\n",
       "      <td>4226</td>\n",
       "      <td>0.928295</td>\n",
       "      <td>0.939605</td>\n",
       "      <td>0.953229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        subgroup  subgroup_size  subgroup_auc  bpsn_auc  \\\n",
       "6                          black           1519      0.812314  0.785562   \n",
       "2      homosexual_gay_or_lesbian           1065      0.814605  0.820933   \n",
       "7                          white           2452      0.835842  0.803607   \n",
       "5                         muslim           2040      0.840519  0.844202   \n",
       "4                         jewish            835      0.881251  0.881476   \n",
       "8  psychiatric_or_mental_illness            511      0.902131  0.871045   \n",
       "0                           male           4386      0.913665  0.902575   \n",
       "1                         female           5155      0.918091  0.914620   \n",
       "3                      christian           4226      0.928295  0.939605   \n",
       "\n",
       "   bnsp_auc  \n",
       "6  0.973499  \n",
       "2  0.962834  \n",
       "7  0.974137  \n",
       "5  0.963600  \n",
       "4  0.964172  \n",
       "8  0.970198  \n",
       "0  0.966827  \n",
       "1  0.963152  \n",
       "3  0.953229  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SUBGROUP_AUC = 'subgroup_auc'\n",
    "BPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\n",
    "BNSP_AUC = 'bnsp_auc'  # stands for background negative, subgroup positive\n",
    "\n",
    "def compute_auc(y_true, y_pred):\n",
    "    try:\n",
    "        return roc_auc_score(y_true, y_pred)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "def compute_subgroup_auc(df, subgroup, label, oof_name):\n",
    "    subgroup_examples = df[df[subgroup]]\n",
    "    return compute_auc(subgroup_examples[label], subgroup_examples[oof_name])\n",
    "\n",
    "def compute_bpsn_auc(df, subgroup, label, oof_name):\n",
    "    \"\"\"Computes the AUC of the within-subgroup negative examples and the background positive examples.\"\"\"\n",
    "    subgroup_negative_examples = df[df[subgroup] & ~df[label]]\n",
    "    non_subgroup_positive_examples = df[~df[subgroup] & df[label]]\n",
    "    examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n",
    "    return compute_auc(examples[label], examples[oof_name])\n",
    "\n",
    "def compute_bnsp_auc(df, subgroup, label, oof_name):\n",
    "    \"\"\"Computes the AUC of the within-subgroup positive examples and the background negative examples.\"\"\"\n",
    "    subgroup_positive_examples = df[df[subgroup] & df[label]]\n",
    "    non_subgroup_negative_examples = df[~df[subgroup] & ~df[label]]\n",
    "    examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n",
    "    return compute_auc(examples[label], examples[oof_name])\n",
    "\n",
    "def compute_bias_metrics_for_model(dataset,\n",
    "                                   subgroups,\n",
    "                                   model,\n",
    "                                   label_col,\n",
    "                                   include_asegs=False):\n",
    "    \"\"\"Computes per-subgroup metrics for all subgroups and one model.\"\"\"\n",
    "    records = []\n",
    "    for subgroup in subgroups:\n",
    "        record = {\n",
    "            'subgroup': subgroup,\n",
    "            'subgroup_size': len(dataset[dataset[subgroup]])\n",
    "        }\n",
    "        record[SUBGROUP_AUC] = compute_subgroup_auc(dataset, subgroup, label_col, model)\n",
    "        record[BPSN_AUC] = compute_bpsn_auc(dataset, subgroup, label_col, model)\n",
    "        record[BNSP_AUC] = compute_bnsp_auc(dataset, subgroup, label_col, model)\n",
    "        records.append(record)\n",
    "    return pd.DataFrame(records).sort_values('subgroup_auc', ascending=True)\n",
    "oof_name = 'predicted_target'\n",
    "bias_metrics_df = compute_bias_metrics_for_model(test_df, identity_columns, oof_name, 'toxicity')\n",
    "bias_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34aca1cf-5b3c-47f9-a140-a7932f55c765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL SCORE IS 0.9111456046087165\n"
     ]
    }
   ],
   "source": [
    "def calculate_overall_auc(df, oof_name):\n",
    "    true_labels = df['toxicity']\n",
    "    predicted_labels = df[oof_name]\n",
    "    return roc_auc_score(true_labels, predicted_labels)\n",
    "\n",
    "def power_mean(series, p):\n",
    "    total = sum(np.power(series, p))\n",
    "    return np.power(total / len(series), 1 / p)\n",
    "\n",
    "def get_final_metric(bias_df, overall_auc, POWER=-5, OVERALL_MODEL_WEIGHT=0.25):\n",
    "    bias_score = np.average([\n",
    "        power_mean(bias_df[SUBGROUP_AUC], POWER),\n",
    "        power_mean(bias_df[BPSN_AUC], POWER),\n",
    "        power_mean(bias_df[BNSP_AUC], POWER)\n",
    "    ])\n",
    "    return (OVERALL_MODEL_WEIGHT * overall_auc) + ((1 - OVERALL_MODEL_WEIGHT) * bias_score)\n",
    "    \n",
    "FINAL_SCORE = get_final_metric(bias_metrics_df, calculate_overall_auc(test_df, oof_name))\n",
    "print(f\"FINAL SCORE IS {FINAL_SCORE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b161948-efb3-40ab-bf26-4692bd158f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# # Save to file in the current working directory\n",
    "pkl_filename = \"logreg_model.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(logreg, file)\n",
    "\n",
    "# Load from file\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    upload_pickle_model = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2890f68-9995-4dec-8cf4-7b92f368bab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = [(train_tfidf_sparse, train_label), (val_tfidf_sparse, val_label)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c6eb04bd-fafa-4b14-ab28-9f12703b53dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.56186\tvalidation_1-logloss:0.56182\n",
      "[1]\tvalidation_0-logloss:0.47311\tvalidation_1-logloss:0.47308\n",
      "[2]\tvalidation_0-logloss:0.40819\tvalidation_1-logloss:0.40827\n",
      "[3]\tvalidation_0-logloss:0.36139\tvalidation_1-logloss:0.36157\n",
      "[4]\tvalidation_0-logloss:0.32739\tvalidation_1-logloss:0.32765\n",
      "[5]\tvalidation_0-logloss:0.30292\tvalidation_1-logloss:0.30330\n",
      "[6]\tvalidation_0-logloss:0.28465\tvalidation_1-logloss:0.28507\n",
      "[7]\tvalidation_0-logloss:0.27087\tvalidation_1-logloss:0.27133\n",
      "[8]\tvalidation_0-logloss:0.25925\tvalidation_1-logloss:0.25977\n",
      "[9]\tvalidation_0-logloss:0.25036\tvalidation_1-logloss:0.25092\n",
      "[10]\tvalidation_0-logloss:0.24376\tvalidation_1-logloss:0.24438\n",
      "[11]\tvalidation_0-logloss:0.23839\tvalidation_1-logloss:0.23912\n",
      "[12]\tvalidation_0-logloss:0.23428\tvalidation_1-logloss:0.23507\n",
      "[13]\tvalidation_0-logloss:0.23099\tvalidation_1-logloss:0.23187\n",
      "[14]\tvalidation_0-logloss:0.22813\tvalidation_1-logloss:0.22908\n",
      "[15]\tvalidation_0-logloss:0.22569\tvalidation_1-logloss:0.22666\n",
      "[16]\tvalidation_0-logloss:0.22355\tvalidation_1-logloss:0.22457\n",
      "[17]\tvalidation_0-logloss:0.22168\tvalidation_1-logloss:0.22279\n",
      "[18]\tvalidation_0-logloss:0.22002\tvalidation_1-logloss:0.22107\n",
      "[19]\tvalidation_0-logloss:0.21838\tvalidation_1-logloss:0.21951\n",
      "[20]\tvalidation_0-logloss:0.21693\tvalidation_1-logloss:0.21814\n",
      "[21]\tvalidation_0-logloss:0.21564\tvalidation_1-logloss:0.21684\n",
      "[22]\tvalidation_0-logloss:0.21431\tvalidation_1-logloss:0.21560\n",
      "[23]\tvalidation_0-logloss:0.21310\tvalidation_1-logloss:0.21440\n",
      "[24]\tvalidation_0-logloss:0.21195\tvalidation_1-logloss:0.21329\n",
      "[25]\tvalidation_0-logloss:0.21097\tvalidation_1-logloss:0.21238\n",
      "[26]\tvalidation_0-logloss:0.20996\tvalidation_1-logloss:0.21143\n",
      "[27]\tvalidation_0-logloss:0.20889\tvalidation_1-logloss:0.21040\n",
      "[28]\tvalidation_0-logloss:0.20796\tvalidation_1-logloss:0.20953\n",
      "[29]\tvalidation_0-logloss:0.20716\tvalidation_1-logloss:0.20878\n",
      "[30]\tvalidation_0-logloss:0.20638\tvalidation_1-logloss:0.20806\n",
      "[31]\tvalidation_0-logloss:0.20554\tvalidation_1-logloss:0.20721\n",
      "[32]\tvalidation_0-logloss:0.20471\tvalidation_1-logloss:0.20639\n",
      "[33]\tvalidation_0-logloss:0.20406\tvalidation_1-logloss:0.20582\n",
      "[34]\tvalidation_0-logloss:0.20325\tvalidation_1-logloss:0.20500\n",
      "[35]\tvalidation_0-logloss:0.20258\tvalidation_1-logloss:0.20431\n",
      "[36]\tvalidation_0-logloss:0.20202\tvalidation_1-logloss:0.20377\n",
      "[37]\tvalidation_0-logloss:0.20138\tvalidation_1-logloss:0.20318\n",
      "[38]\tvalidation_0-logloss:0.20059\tvalidation_1-logloss:0.20246\n",
      "[39]\tvalidation_0-logloss:0.20002\tvalidation_1-logloss:0.20194\n",
      "[40]\tvalidation_0-logloss:0.19941\tvalidation_1-logloss:0.20133\n",
      "[41]\tvalidation_0-logloss:0.19886\tvalidation_1-logloss:0.20078\n",
      "[42]\tvalidation_0-logloss:0.19824\tvalidation_1-logloss:0.20018\n",
      "[43]\tvalidation_0-logloss:0.19771\tvalidation_1-logloss:0.19967\n",
      "[44]\tvalidation_0-logloss:0.19707\tvalidation_1-logloss:0.19906\n",
      "[45]\tvalidation_0-logloss:0.19653\tvalidation_1-logloss:0.19856\n",
      "[46]\tvalidation_0-logloss:0.19609\tvalidation_1-logloss:0.19813\n",
      "[47]\tvalidation_0-logloss:0.19560\tvalidation_1-logloss:0.19770\n",
      "[48]\tvalidation_0-logloss:0.19521\tvalidation_1-logloss:0.19732\n",
      "[49]\tvalidation_0-logloss:0.19480\tvalidation_1-logloss:0.19698\n",
      "[50]\tvalidation_0-logloss:0.19427\tvalidation_1-logloss:0.19647\n",
      "[51]\tvalidation_0-logloss:0.19387\tvalidation_1-logloss:0.19608\n",
      "[52]\tvalidation_0-logloss:0.19342\tvalidation_1-logloss:0.19567\n",
      "[53]\tvalidation_0-logloss:0.19305\tvalidation_1-logloss:0.19531\n",
      "[54]\tvalidation_0-logloss:0.19270\tvalidation_1-logloss:0.19497\n",
      "[55]\tvalidation_0-logloss:0.19234\tvalidation_1-logloss:0.19463\n",
      "[56]\tvalidation_0-logloss:0.19194\tvalidation_1-logloss:0.19425\n",
      "[57]\tvalidation_0-logloss:0.19160\tvalidation_1-logloss:0.19391\n",
      "[58]\tvalidation_0-logloss:0.19124\tvalidation_1-logloss:0.19357\n",
      "[59]\tvalidation_0-logloss:0.19099\tvalidation_1-logloss:0.19335\n",
      "[60]\tvalidation_0-logloss:0.19063\tvalidation_1-logloss:0.19299\n",
      "[61]\tvalidation_0-logloss:0.19033\tvalidation_1-logloss:0.19272\n",
      "[62]\tvalidation_0-logloss:0.19001\tvalidation_1-logloss:0.19240\n",
      "[63]\tvalidation_0-logloss:0.18970\tvalidation_1-logloss:0.19211\n",
      "[64]\tvalidation_0-logloss:0.18935\tvalidation_1-logloss:0.19177\n",
      "[65]\tvalidation_0-logloss:0.18907\tvalidation_1-logloss:0.19149\n",
      "[66]\tvalidation_0-logloss:0.18876\tvalidation_1-logloss:0.19120\n",
      "[67]\tvalidation_0-logloss:0.18844\tvalidation_1-logloss:0.19092\n",
      "[68]\tvalidation_0-logloss:0.18812\tvalidation_1-logloss:0.19063\n",
      "[69]\tvalidation_0-logloss:0.18792\tvalidation_1-logloss:0.19045\n",
      "[70]\tvalidation_0-logloss:0.18761\tvalidation_1-logloss:0.19016\n",
      "[71]\tvalidation_0-logloss:0.18727\tvalidation_1-logloss:0.18982\n",
      "[72]\tvalidation_0-logloss:0.18694\tvalidation_1-logloss:0.18950\n",
      "[73]\tvalidation_0-logloss:0.18665\tvalidation_1-logloss:0.18923\n",
      "[74]\tvalidation_0-logloss:0.18638\tvalidation_1-logloss:0.18897\n",
      "[75]\tvalidation_0-logloss:0.18611\tvalidation_1-logloss:0.18873\n",
      "[76]\tvalidation_0-logloss:0.18590\tvalidation_1-logloss:0.18852\n",
      "[77]\tvalidation_0-logloss:0.18568\tvalidation_1-logloss:0.18832\n",
      "[78]\tvalidation_0-logloss:0.18545\tvalidation_1-logloss:0.18811\n",
      "[79]\tvalidation_0-logloss:0.18517\tvalidation_1-logloss:0.18786\n",
      "[80]\tvalidation_0-logloss:0.18502\tvalidation_1-logloss:0.18773\n",
      "[81]\tvalidation_0-logloss:0.18477\tvalidation_1-logloss:0.18748\n",
      "[82]\tvalidation_0-logloss:0.18454\tvalidation_1-logloss:0.18726\n",
      "[83]\tvalidation_0-logloss:0.18432\tvalidation_1-logloss:0.18705\n",
      "[84]\tvalidation_0-logloss:0.18409\tvalidation_1-logloss:0.18682\n",
      "[85]\tvalidation_0-logloss:0.18387\tvalidation_1-logloss:0.18663\n",
      "[86]\tvalidation_0-logloss:0.18367\tvalidation_1-logloss:0.18645\n",
      "[87]\tvalidation_0-logloss:0.18346\tvalidation_1-logloss:0.18624\n",
      "[88]\tvalidation_0-logloss:0.18327\tvalidation_1-logloss:0.18607\n",
      "[89]\tvalidation_0-logloss:0.18311\tvalidation_1-logloss:0.18591\n",
      "[90]\tvalidation_0-logloss:0.18287\tvalidation_1-logloss:0.18568\n",
      "[91]\tvalidation_0-logloss:0.18272\tvalidation_1-logloss:0.18554\n",
      "[92]\tvalidation_0-logloss:0.18255\tvalidation_1-logloss:0.18538\n",
      "[93]\tvalidation_0-logloss:0.18236\tvalidation_1-logloss:0.18521\n",
      "[94]\tvalidation_0-logloss:0.18222\tvalidation_1-logloss:0.18510\n",
      "[95]\tvalidation_0-logloss:0.18202\tvalidation_1-logloss:0.18491\n",
      "[96]\tvalidation_0-logloss:0.18183\tvalidation_1-logloss:0.18475\n",
      "[97]\tvalidation_0-logloss:0.18163\tvalidation_1-logloss:0.18454\n",
      "[98]\tvalidation_0-logloss:0.18144\tvalidation_1-logloss:0.18437\n",
      "[99]\tvalidation_0-logloss:0.18126\tvalidation_1-logloss:0.18420\n",
      "CPU times: user 44min 1s, sys: 2.5 s, total: 44min 3s\n",
      "Wall time: 29min 48s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.82,\n",
       "              early_stopping_rounds=10, enable_categorical=False, eta=0.2,\n",
       "              eval_metric=None, gamma=2.5, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.200000003, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=4,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=103.0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.82,\n",
       "              early_stopping_rounds=10, enable_categorical=False, eta=0.2,\n",
       "              eval_metric=None, gamma=2.5, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.200000003, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=4,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=103.0, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.82,\n",
       "              early_stopping_rounds=10, enable_categorical=False, eta=0.2,\n",
       "              eval_metric=None, gamma=2.5, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.200000003, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=4,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=103.0, ...)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# fit model no training data\n",
    "xgb_model = XGBClassifier(\n",
    "    max_depth=6,\n",
    "    eta=0.2,\n",
    "    gamma=2.5,\n",
    "    min_child_weight=4,\n",
    "    subsample=0.5,\n",
    "    reg_alpha=103.0, reg_lambda=0.913,\n",
    "    verbosity=1,\n",
    "    colsample_bytree=0.82,\n",
    "    early_stopping_rounds=10, \n",
    "    objective='binary:logistic',\n",
    "    )\n",
    "xgb_model.fit(train_tfidf_sparse, train_label, eval_set=evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4b154581-6ba2-4583-8906-8f930e224a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.82,\n",
       "              early_stopping_rounds=10, enable_categorical=False, eta=0.2,\n",
       "              eval_metric=None, gamma=2.5, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.200000003, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=4,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=103.0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.82,\n",
       "              early_stopping_rounds=10, enable_categorical=False, eta=0.2,\n",
       "              eval_metric=None, gamma=2.5, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.200000003, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=4,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=103.0, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.82,\n",
       "              early_stopping_rounds=10, enable_categorical=False, eta=0.2,\n",
       "              eval_metric=None, gamma=2.5, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.200000003, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=4,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=103.0, ...)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "05c56b4b-abcf-4fa6-94e8-4e4e2974b7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.save_model(\"model_xgb.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "883f0e35-df65-416a-910b-3f0e32f412a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_model2 = xgb.XGBClassifier()\n",
    "# xgb_model2.load_model(\"model_xgb.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b1ab7632-5453-43f4-8153-9931ce1a3602",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (1) does not match length of index (194641)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [61]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m oof_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_target_xgb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtest_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43moof_name\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m xgb_model\u001b[38;5;241m.\u001b[39mpredict_proba(test_tfidf_sparse)[:, \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/godel/lib/python3.9/site-packages/pandas/core/frame.py:3655\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3652\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3653\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3654\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 3655\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/godel/lib/python3.9/site-packages/pandas/core/frame.py:3832\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3822\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3823\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3824\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   3825\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3830\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   3831\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3832\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3834\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3835\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   3836\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   3837\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   3838\u001b[0m     ):\n\u001b[1;32m   3839\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   3840\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/.conda/envs/godel/lib/python3.9/site-packages/pandas/core/frame.py:4535\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   4534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 4535\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4536\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/godel/lib/python3.9/site-packages/pandas/core/common.py:557\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[0;32m--> 557\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    558\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    559\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    560\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    561\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    562\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (1) does not match length of index (194641)"
     ]
    }
   ],
   "source": [
    "oof_name = 'predicted_target_xgb'\n",
    "test_df[oof_name] = xgb_model.predict_proba(test_tfidf_sparse)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d59b7a-630d-4a68-8727-1131cfcfd350",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_metrics_df = compute_bias_metrics_for_model(test_df, identity_columns, oof_name, 'toxicity')\n",
    "bias_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8496dc7-da7f-4f4a-96b8-9ee1499f0fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_SCORE = get_final_metric(bias_metrics_df, calculate_overall_auc(test_df, oof_name))\n",
    "print(f\"FINAL SCORE IS {FINAL_SCORE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7c19d398-fb45-4d19-b6aa-bd42ca2d34ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: you've fucked up Fd asshole $5, Logreg = 0.9944592462545216\n",
      "Text: 55 go fuck yourself, fuckin' fuck. Die!@, Logreg = 0.9983772480620811\n",
      "Text: I am lesbian and I proud of it, Logreg = 0.23600877048268767\n",
      "Text: BLM, Logreg = 0.04387685089123575\n",
      "Text: BLM sucks, Logreg = 0.9864814460174348\n",
      "Text: I think people like you should die, Logreg = 0.515300779442672\n",
      "Text: I love you friends, Logreg = 0.013271473103748214\n",
      "Text: BLM $uck$, Logreg = 0.06574767966618525\n",
      "Text: I hate software development, Logreg = 0.01869637873081117\n",
      "Text: I hate software development and you, Logreg = 0.0261994046957514\n",
      "Text: Go and kill this motherfucke, Logreg = 0.9565406708712991\n"
     ]
    }
   ],
   "source": [
    "test_strings = [\"you've fucked up Fd asshole $5\", \"55 go fuck yourself, fuckin' fuck. Die!@\", \"I am lesbian and I proud of it\",\n",
    "               \"BLM\", \"BLM sucks\", \"I think people like you should die\", \"I love you friends\", \"BLM $uck$\",\n",
    "               \"I hate software development\", \"I hate software development and you\", \n",
    "               \"Go and kill this motherfucke\"]\n",
    "\n",
    "for text in test_strings:\n",
    "    line = replace_typical_misspell(text)\n",
    "    line = clean_text(line)\n",
    "    line = clean_numbers(line)\n",
    "    bow = [dictionary.doc2bow(doc, allow_update=False) for doc in simple_preproc([line])]\n",
    "    test_tfidf = tfidf[bow]\n",
    "    test_tfidf_sparse = corpus2csc(test_tfidf, num_terms=num_terms).T\n",
    "    preds_lr = upload_pickle_model.predict_proba(test_tfidf_sparse)[:, 1]\n",
    "    # preds_xgb = model.predict_proba(test_tfidf_sparse)[:, 1]\n",
    "    print(f\"Text: {text}, Logreg = {preds_lr[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40f2209-4495-4d2c-84b2-89cd98f3bd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "894b3e99-8870-41ac-a549-da6a78a42091",
   "metadata": {},
   "outputs": [],
   "source": [
    "space={'max_depth': hp.quniform(\"max_depth\", 3, 18, 1),\n",
    "        'gamma': hp.uniform ('gamma', 1,9),\n",
    "        'reg_alpha' : hp.quniform('reg_alpha', 40,180,1),\n",
    "        'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n",
    "        'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "        'n_estimators': 200,\n",
    "        'seed': SEED\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2daafdeb-66fb-4965-8b50-1e76517edf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "def objective(space):\n",
    "    clf=xgb.XGBClassifier(\n",
    "                    n_estimators =space['n_estimators'], max_depth = int(space['max_depth']), gamma = space['gamma'],\n",
    "                    reg_alpha = int(space['reg_alpha']), min_child_weight=int(space['min_child_weight']),\n",
    "                    colsample_bytree=int(space['colsample_bytree']),\n",
    "                    verbosity=1, objective='binary:logistic', eval_metric=\"auc\", early_stopping_rounds=10)\n",
    "    \n",
    "    evaluation = [(train_tfidf_sparse, train_label), (val_tfidf_sparse, val_label)]\n",
    "    \n",
    "    clf.fit(train_tfidf_sparse,\n",
    "            train_label,\n",
    "            eval_set=evaluation,\n",
    "            verbose=False)\n",
    "    \n",
    "\n",
    "    pred = clf.predict(val_tfidf_sparse)\n",
    "    score = roc_auc_score(val_label, pred>0.7)\n",
    "    scores.append(score)\n",
    "    return {'loss': -score, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9e949095-a625-43b6-8b11-9b9be76624db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [17:08<00:00, 10.29s/trial, best loss: -0.5]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective,\n",
    "                        space = space,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 100,\n",
    "                        trials = trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "98e77f34-71e0-411a-a93e-363f58c96cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters are : \n",
      "{'colsample_bytree': 0.8261009556047648, 'gamma': 2.5362056282767274, 'max_depth': 6.0, 'min_child_weight': 4.0, 'reg_alpha': 103.0, 'reg_lambda': 0.9139711787883124}\n"
     ]
    }
   ],
   "source": [
    "print(f\"The best hyperparameters are : \\n{best_hyperparams}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf4f2ec-421f-402a-a973-d73ea3c61eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "godel:Python",
   "language": "python",
   "name": "conda-env-godel-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
