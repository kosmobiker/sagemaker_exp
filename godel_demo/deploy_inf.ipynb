{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f81ba92d-2dda-4d9e-9839-faa7b1c9a547",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import IPython\n",
    "import sys\n",
    "\n",
    "# !{sys.executable} -m pip install ipywidgets\n",
    "# IPython.Application.instance().kernel.do_shutdown(True)  # has to restart kernel so changes are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "11b3684e-2571-420b-9ffb-6c63c627e392",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# !pip install -U transformers\n",
    "# !pip install -U sagemaker\n",
    "# !pip install torch==1.11.0\n",
    "# !pip install torchtext==0.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6675e82c-a170-4c1e-a969-d7a92d7db9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import sagemaker\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "import boto3\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from pathlib import Path\n",
    "\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "from sagemaker.predictor import Predictor\n",
    "from datetime import datetime\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "from datetime import datetime\n",
    "import threading\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f7378f80-1708-4e9c-a267-03ccd2f4910d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker bucket: sagemaker-godeltech\n",
      "sagemaker session region: eu-west-1\n"
     ]
    }
   ],
   "source": [
    "sess = sagemaker.Session()\n",
    "sagemaker_session_bucket = 'sagemaker-godeltech'\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "#put SageMaker role here if you're running this notebook locally\n",
    "role = os.getenv('SAGEMAKER_ROLE')\n",
    "\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "21a9ce0d-922a-4cad-b270-9821e9a0f8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'unitary/unbiased-toxic-roberta'\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, return_dict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ff746e80-f8fa-49af-9086-cccc80d1f8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory for model artifacts\n",
    "Path(\"normal_model/\").mkdir(exist_ok=True)\n",
    "Path(\"traced_model/\").mkdir(exist_ok=True)\n",
    "\n",
    "# Prepare sample input for jit model tracing\n",
    "seq = \"\"\"\n",
    "Odin’s attitude was similar to that of the hero of German philosopher Friedrich Nietzsche’s Thus Spoke Zarathustra: “You say it is the good cause\n",
    "that hallows even war? I say unto you: it is the good war that hallows any cause.” Odin boasts in the Eddic poem The Song of Gray-Beard, \n",
    "“I incited the princes never to make peace.\n",
    "\"\"\"\n",
    "max_length = 512\n",
    "\n",
    "tokenized_sequence_pair = tokenizer.encode_plus(\n",
    "    seq, max_length=max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "example = tokenized_sequence_pair[\"input_ids\"], tokenized_sequence_pair[\"attention_mask\"]\n",
    "\n",
    "traced_model = torch.jit.trace(model.eval(), example)\n",
    "\n",
    "model.save_pretrained('normal_model/')\n",
    "traced_model.save(\"traced_model/model.pth\") # The `.pth` extension is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "dcfae3c2-bb47-4816-b2dd-3e0cf00df707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./\n",
      "./config.json\n",
      "./pytorch_model.bin\n",
      "./\n",
      "./model.pth\n"
     ]
    }
   ],
   "source": [
    "!tar -czvf normal_model.tar.gz -C normal_model . && mv normal_model.tar.gz normal_model/\n",
    "!tar -czvf traced_model.tar.gz -C traced_model . && mv traced_model.tar.gz traced_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "16e5eb2d-9f7a-4984-9ed7-0504be9ab116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files were uploaded\n"
     ]
    }
   ],
   "source": [
    "normal_model_url = sess.upload_data(\n",
    "    path=\"normal_model/normal_model.tar.gz\",\n",
    "    key_prefix=\"neuron-experiments/normal-model\",\n",
    ")\n",
    "\n",
    "traced_model_url = sess.upload_data(\n",
    "    path=\"traced_model/traced_model.tar.gz\",\n",
    "    key_prefix=\"neuron-experiments/traced-model\",\n",
    ")\n",
    "print('Files were uploaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c829e90e-422f-46c6-84f6-ace36e262489",
   "metadata": {},
   "outputs": [],
   "source": [
    "flavour = \"normal\"\n",
    "hardware = \"g4dn\"\n",
    "date_string = datetime.now().strftime(\"%Y%m-%d%H-%M%S\")\n",
    "\n",
    "prefix = \"neuron-experiments/toxic-bert\"\n",
    "flavour = \"normal\"\n",
    "date_string = datetime.now().strftime(\"%Y%m-%d%H-%M%S\")\n",
    "\n",
    "normal_sm_model = HuggingFaceModel(\n",
    "    model_data=normal_model_url,\n",
    "    predictor_cls=Predictor,\n",
    "    transformers_version=\"4.12.3\",\n",
    "    pytorch_version='1.9.1',\n",
    "    role=role,\n",
    "    entry_point=\"inference_gpuinf1.py\",\n",
    "    source_dir=\"aux\",\n",
    "    py_version=\"py38\",\n",
    "    name=f\"{flavour}-toxicbert-{date_string}\",\n",
    "    env={\"SAGEMAKER_CONTAINER_LOG_LEVEL\": \"10\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ec247894-df70-47eb-86e1-8fb337bd9680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!CPU times: user 35.3 s, sys: 5.34 s, total: 40.6 s\n",
      "Wall time: 11min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "normal_predictor = normal_sm_model.deploy(\n",
    "    instance_type=\"ml.g4dn.xlarge\",\n",
    "    initial_instance_count=1,\n",
    "    endpoint_name=f\"toxicbert-{flavour}-{hardware}-{date_string}\",\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6a0494b9-48e0-4606-9141-9f3c5c22e75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kayne_west_tweet = \"\"\"\n",
    "I’m a bit sleepy tonight but when I wake up I’m going death con 3 On JEWISH PEOPLE.\n",
    "The funny thing is I actually can’t be Anti Semitic because black people are actually Jew \n",
    "also You guys have toyed with me and tried to black ball anyone whoever opposes your agenda.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "134055a8-992e-4777-9973-4d1057a5295a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compilation_job_name = name_from_base(\"godel\")\n",
    "hardware = \"inf1\"\n",
    "output_model_path = f\"s3://{sagemaker_session_bucket}/{prefix}/neo-compilations/{hardware}-model\"\n",
    "\n",
    "compiled_inf1_model = HuggingFaceModel(\n",
    "    model_data=traced_model_url,\n",
    "    predictor_cls=Predictor,\n",
    "    transformers_version=\"4.12.3\",\n",
    "    pytorch_version='1.9.1',\n",
    "    role=role,\n",
    "    entry_point=\"inference_gpuinf1.py\",\n",
    "    source_dir=\"aux\",\n",
    "    py_version=\"py37\",\n",
    "    name=f\"toxicbert-inf1-{date_string}\",\n",
    "    env={\"SAGEMAKER_CONTAINER_LOG_LEVEL\": \"10\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "18a1e26f-50c8-43ff-a283-07495db322c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "??????????????????????????????............................................................................................................!CPU times: user 641 ms, sys: 165 ms, total: 806 ms\n",
      "Wall time: 11min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "compiled_inf1_model = compiled_inf1_model.compile(\n",
    "    target_instance_family=f\"ml_{hardware}\",\n",
    "    input_shape={\"input_ids\": [1, 512], \"attention_mask\": [1, 512]},\n",
    "    job_name=compilation_job_name,\n",
    "    role=role,\n",
    "    framework=\"pytorch\",\n",
    "    framework_version=\"1.9.1\",\n",
    "    output_path=output_model_path,\n",
    "    compiler_options=json.dumps(\"--dtype int64\"),\n",
    "    compile_max_run=900,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "972846aa-72e1-421f-a5b2-f30244d976bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!CPU times: user 16.7 s, sys: 2.74 s, total: 19.5 s\n",
      "Wall time: 6min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "compiled_inf1_predictor = compiled_inf1_model.deploy(\n",
    "    instance_type=\"ml.inf1.xlarge\",\n",
    "    initial_instance_count=1,\n",
    "    endpoint_name=f\"toxicbert-{hardware}-{date_string}\",\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "dfcbe593-1a30-4457-afff-96c1af56e0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_preds = 1000\n",
    "num_threads = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "99c3e7f2-71e6-4174-ad68-0219e7459b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread 140546579347008 started\n",
      "Thread 140546570954304 started\n",
      "Thread 140546528990784 started\n",
      "Thread 140546596132416 started\n",
      "Thread 140546630743616 started\n"
     ]
    }
   ],
   "source": [
    "gpu_times = []\n",
    "gpu_threads = []\n",
    "\n",
    "\n",
    "def gpu_predict():\n",
    "    thread_id = threading.get_ident()\n",
    "    print(f\"Thread {thread_id} started\")\n",
    "\n",
    "    for i in range(num_preds):\n",
    "        tick = time.time()\n",
    "        response = normal_predictor.predict(seq)\n",
    "        tock = time.time()\n",
    "        gpu_times.append((thread_id, tock - tick))\n",
    "\n",
    "\n",
    "[gpu_threads.append(threading.Thread(target=gpu_predict, daemon=False)) for i in range(num_threads)]\n",
    "[gpu_t.start() for gpu_t in gpu_threads]\n",
    "\n",
    "# Wait for threads, get an estimate of total time\n",
    "start = time.time()\n",
    "[gpu_t.join() for gpu_t in gpu_threads]\n",
    "end = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "1803d8c8-e6ff-4538-a740-3207755dd7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_TPS = (num_preds * num_threads) / end\n",
    "\n",
    "gpu_t = [duration for thread__id, duration in gpu_times]\n",
    "gpu_latency_percentiles = np.percentile(gpu_t, q=[50, 90, 95, 99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "d32135c7-594c-4ef7-8b8e-589993aa3f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread 140546570954304 startedThread 140546596132416 started\n",
      "Thread 140546630743616 started\n",
      "\n",
      "Thread 140546528990784 started\n",
      "Thread 140546604525120 started\n"
     ]
    }
   ],
   "source": [
    "inf_times = []\n",
    "inf_threads = []\n",
    "\n",
    "def inf_predict():\n",
    "    thread_id = threading.get_ident()\n",
    "    print(f\"Thread {thread_id} started\")\n",
    "\n",
    "    for i in range(num_preds):\n",
    "        tick = time.time()\n",
    "        response = compiled_inf1_predictor.predict(seq)\n",
    "        tock = time.time()\n",
    "        inf_times.append((thread_id, tock - tick))\n",
    "\n",
    "\n",
    "\n",
    "[inf_threads.append(threading.Thread(target=inf_predict, daemon=False)) for i in range(num_threads)]\n",
    "[inf_t.start() for inf_t in inf_threads]\n",
    "\n",
    "# Wait for threads, get an estimate of total time\n",
    "start = time.time()\n",
    "[inf_t.join() for inf_t in inf_threads]\n",
    "end = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "682859ed-9719-4ae4-9d55-667e1f35dbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "INF_TPS = (num_preds * num_threads) / end\n",
    "\n",
    "inf_t = [duration for thread__id, duration in inf_times]\n",
    "inf_latency_percentiles = np.percentile(inf_t, q=[50, 90, 95, 99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "cb0e86c1-d8af-4366-8a0d-b81d5569fe8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.linspace(0, 0.5, 101)\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.hist(gpu_t, bins, alpha=0.5, label='GPU', color='lime')\n",
    "plt.hist(inf_t, bins, alpha=0.5, label='Inf1', color='orange')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title(\"HuggingFace model GPU/Inferentia benchmark\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "0defc8ad-dc6c-4a7a-8646-0cd36cc78bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>50</th>\n",
       "      <th>90</th>\n",
       "      <th>95</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GPU</th>\n",
       "      <td>0.177562</td>\n",
       "      <td>0.191632</td>\n",
       "      <td>0.200528</td>\n",
       "      <td>0.355553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inf1</th>\n",
       "      <td>0.085264</td>\n",
       "      <td>0.098579</td>\n",
       "      <td>0.107379</td>\n",
       "      <td>0.285039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            50        90        95        99\n",
       "GPU   0.177562  0.191632  0.200528  0.355553\n",
       "Inf1  0.085264  0.098579  0.107379  0.285039"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latency_df = pd.DataFrame([gpu_latency_percentiles, inf_latency_percentiles], index=['GPU', 'Inf1'], columns=[50, 90, 95, 99])\n",
    "latency_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "8b26b8b5-dad6-413e-b80c-eae5fc0e9970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: Rough request throughput/second is 27.69804758053417\n",
      "Inferentia: Rough request throughput/second is 52.232144669515655\n"
     ]
    }
   ],
   "source": [
    "print(f\"GPU: Rough request throughput/second is {GPU_TPS}\")\n",
    "print(f\"Inferentia: Rough request throughput/second is {INF_TPS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c85908b3-286e-48c4-adb8-73f3630846e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_predictor.delete_model()\n",
    "normal_predictor.delete_endpoint()\n",
    "compiled_inf1_predictor.delete_model()\n",
    "compiled_inf1_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3b3ca7-9b59-4054-84a7-48eea92331b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2b3b57-696f-4bcf-beb4-38b438192b37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afbeb71-c868-48be-82a9-5d0f1a0777a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f210c7d-2f96-4127-9312-ea82ccee4449",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Godel",
   "language": "python",
   "name": "godel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
