{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaacc986-d043-4874-b798-2c8003887229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "from sagemaker.async_inference.async_inference_config import AsyncInferenceConfig\n",
    "from sagemaker.s3 import s3_path_join\n",
    "from sagemaker.async_inference.waiter_config import WaiterConfig\n",
    "\n",
    "import pandas as pd\n",
    "import awswrangler as wr\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import threading\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#SageMaker Role\n",
    "ROLE = os.getenv('SAGEMAKER_ROLE')\n",
    "# Hub Model configuration. https://huggingface.co/models\n",
    "hub = {\n",
    "    'HF_MODEL_ID':'unitary/unbiased-toxic-roberta',\n",
    "    'HF_TASK':'text-classification'\n",
    "}\n",
    "# sagemaker_session_bucket = 'sagemaker-godeltech'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9de3b75c-6d2c-489f-a1c0-b33d776cd014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    transformers_version='4.17.0',\n",
    "    pytorch_version='1.10.2',\n",
    "    py_version='py38',\n",
    "    env=hub,\n",
    "    role=ROLE\n",
    ")\n",
    "\n",
    "# deploy model to SageMaker Inference\n",
    "realtime_predictor = huggingface_model.deploy(\n",
    "        initial_instance_count=1, # number of instances\n",
    "        instance_type='ml.m5.xlarge', # ec2 instance type\n",
    "        endpoint_name=f\"toxicbert-huggingdace-realtime\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9144b90b-40b7-423c-a39d-a179d77bf032",
   "metadata": {},
   "outputs": [],
   "source": [
    "##let's try on kayne west scandal tweet https://pitchfork.com/news/kanye-west-locked-out-of-twitter-following-anti-semitic-tweet/\n",
    "\n",
    "kayne_west_tweet = \"\"\"\n",
    "I’m a bit sleepy tonight but when I wake up I’m going death con 3 On JEWISH PEOPLE.\n",
    "The funny thing is I actually can’t be Anti Semitic because black people are actually Jew \n",
    "also You guys have toyed with me and tried to black ball anyone whoever opposes your agenda.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eca15e13-0511-45a5-849d-31023dfc6e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 78.1 ms, sys: 0 ns, total: 78.1 ms\n",
      "Wall time: 865 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'jewish', 'score': 0.9979433417320251}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "realtime_predictor.predict({\"inputs\" : kayne_west_tweet})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9878747b-2267-4621-8239-513b63bc7c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "# create async endpoint configuration\n",
    "async_config = AsyncInferenceConfig(\n",
    "    output_path=s3_path_join(\"s3://\", sagemaker_session_bucket, \"transformers/async_predict/outputs\") , # Where our results will be stored\n",
    ")\n",
    "\n",
    "# deploy the endpoint endpoint\n",
    "async_predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    async_inference_config=async_config,\n",
    "    endpoint_name=f\"toxicbert-huggingdace-asynch\"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4397d1e4-ea5b-46e3-8828-f83dec974573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'jewish', 'score': 0.9979433417320251}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async_predictor.predict({\"inputs\" : kayne_west_tweet})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0124c223-4338-4d45-a64c-b0c7be4e6780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'jewish', 'score': 0.9979433417320251}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = async_predictor.predict_async({\"inputs\" : kayne_west_tweet})\n",
    "\n",
    "config = WaiterConfig(\n",
    "  max_attempts=5, #  number of attempts\n",
    "  delay=10 #  time in seconds to wait between attempts\n",
    "  )\n",
    "\n",
    "resp.get_result(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f10d67d2-6159-44f2-9baf-b49e7596b9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TIMES = 1_000\n",
    "TEST_PATH = f\"s3://{sagemaker_session_bucket}/data/test/test.csv\"\n",
    "test = wr.s3.read_csv([TEST_PATH]).iloc[:N_TIMES, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be06a2c1-fba6-4411-b577-446866544594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response object: <sagemaker.async_inference.async_inference_response.AsyncInferenceResponse object at 0x7f5fa6ecf0a0>\n",
      "Response output path: s3://sagemaker-godeltech/transformers/async_predict/outputs/e55b3128-a8af-40d2-9872-26cfa409b527.out\n",
      "Start Polling to get response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'white', 'score': 0.9930591583251953}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_list = []\n",
    "for text in test:\n",
    "    resp = async_predictor.predict_async(data={\"inputs\": text})\n",
    "    output_list.append(resp)\n",
    "\n",
    "print(f\"Response object: {resp}\")\n",
    "print(f\"Response output path: {resp.output_path}\")\n",
    "print(\"Start Polling to get response:\")\n",
    "\n",
    "config = WaiterConfig(\n",
    "  max_attempts=5, #  number of attempts\n",
    "  delay=10 #  time in seconds to wait between attempts\n",
    "  )\n",
    "\n",
    "resp.get_result(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b166706c-822c-4724-bba8-f862989c1054",
   "metadata": {},
   "outputs": [],
   "source": [
    "realtime_predictor.delete_model()\n",
    "realtime_predictor.delete_endpoint()\n",
    "async_predictor.delete_model()\n",
    "async_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26e99c4-55b1-45e5-9684-3852827e8f62",
   "metadata": {},
   "source": [
    "Sagemaker endpoints *are not publicly exposed* to the Internet. So, you'll need some way of creating a public HTTP endpoint that can route requests to your Sagemaker endpoint. One way you can do this is with an AWS Lambda function fronted by API gateway.\n",
    "\n",
    ">API Gateway -> Lambda -> Sagemaker endpoint\n",
    "\n",
    "Basic example is here https://aws.amazon.com/blogs/machine-learning/call-an-amazon-sagemaker-model-endpoint-using-amazon-api-gateway-and-aws-lambda/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddc694b-e27f-4d00-8dad-e28a415432ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Godel",
   "language": "python",
   "name": "godel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
